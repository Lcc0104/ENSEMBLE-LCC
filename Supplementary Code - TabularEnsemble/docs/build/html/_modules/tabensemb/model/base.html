
<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>tabensemb.model.base &#8212; Tabular Ensemble 0.2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx_paramlinks.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/nbsphinx_dataframe.css?v=60cbb005" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script src="../../../_static/documentation_options.js?v=3b889da3"></script>
    <script src="../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/tabensemb/model/base';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    <p class="title logo__title">Tabular Ensemble 0.2 documentation</p>
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../examples/get_started.html">
                        Get Started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../examples/advanced_usage.html">
                        Advanced Usage
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../api/api.html">
                        API References
                      </a>
                    </li>
                
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/ANONYMOUS/tabular_ensemble" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../examples/get_started.html">
                        Get Started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../examples/advanced_usage.html">
                        Advanced Usage
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../api/api.html">
                        API References
                      </a>
                    </li>
                
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/ANONYMOUS/tabular_ensemble" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">tabensemb.model.base</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <h1>Source code for tabensemb.model.base</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">types</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch.optim.optimizer</span>
<span class="kn">import</span> <span class="nn">tabensemb</span>
<span class="kn">from</span> <span class="nn">tabensemb.utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">tabensemb.trainer</span> <span class="kn">import</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">save_trainer</span>
<span class="kn">from</span> <span class="nn">tabensemb.data</span> <span class="kn">import</span> <span class="n">DataModule</span>
<span class="kn">import</span> <span class="nn">skopt</span>
<span class="kn">from</span> <span class="nn">skopt</span> <span class="kn">import</span> <span class="n">gp_minimize</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">Data</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span> <span class="k">as</span> <span class="n">cp</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">skopt.space</span> <span class="kn">import</span> <span class="n">Real</span><span class="p">,</span> <span class="n">Integer</span><span class="p">,</span> <span class="n">Categorical</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning</span> <span class="kn">import</span> <span class="n">Callback</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.callbacks</span> <span class="kn">import</span> <span class="n">EarlyStopping</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Iterable</span>
<span class="kn">from</span> <span class="nn">captum.attr</span> <span class="kn">import</span> <span class="n">FeaturePermutation</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">packaging</span> <span class="kn">import</span> <span class="n">version</span>


<div class="viewcode-block" id="AbstractModel">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.html#tabensemb.model.AbstractModel">[docs]</a>
<span class="k">class</span> <span class="nc">AbstractModel</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The base class for all model bases.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    exclude_models</span>
<span class="sd">        The names of models that should not be trained.</span>
<span class="sd">    init_params</span>
<span class="sd">        Arguments passed to :meth:`__init__`. See :meth:`save_kwargs`.</span>
<span class="sd">    limit_batch_size</span>
<span class="sd">        If ``batch_size // len(training set) &lt; limit_batch_size``, the ``batch_size`` is forced to be</span>
<span class="sd">        ``len(training set)`` to avoid potential numerical issues. For Tabnet, this is extremely important because a</span>
<span class="sd">        small batch may cause NaNs and further CUDA device-side assert in the sparsemax function. Set to -1 to turn off</span>
<span class="sd">        this check (NOT RECOMMENDED!!). Note: Setting ``drop_last=True`` for ``torch.utils.data.DataLoader`` is fine,</span>
<span class="sd">        but I think (i) having access to all data points in one epoch is beneficial for some models, (ii) If using a</span>
<span class="sd">        large dataset and a large ``batch_size``, it is possible that the last batch is so large that contains</span>
<span class="sd">        essential information, (iii) the user should have full control for this. If you want to use ``drop_last`` in</span>
<span class="sd">        your code, use the ``original_batch_size`` in ``kwargs`` passed to :class:`AbstractModel` methods.</span>
<span class="sd">    train_losses</span>
<span class="sd">        The training loss during training of each model.</span>
<span class="sd">    val_losses</span>
<span class="sd">        The validation loss during training of each model.</span>
<span class="sd">    restored_epochs</span>
<span class="sd">        The best epoch from where the model is restored after training.</span>
<span class="sd">    model</span>
<span class="sd">        A dictionary of models.</span>
<span class="sd">    model_params</span>
<span class="sd">        Hyperparameters that contain all keys in :meth:`_initial_values` for each model. In cross validation runs, the</span>
<span class="sd">        parameters in the previous run will be loaded for the current run.</span>
<span class="sd">    model_subset</span>
<span class="sd">        The names of models selected to be trained in the model base.</span>
<span class="sd">    program</span>
<span class="sd">        The name of the model base.</span>
<span class="sd">    root</span>
<span class="sd">        The place where all files of the model base are stored.</span>
<span class="sd">    store_in_harddisk</span>
<span class="sd">        Whether to save models in the hard disk.</span>
<span class="sd">    trainer</span>
<span class="sd">        A :class:`tabensemb.trainer.Trainer` instance.</span>
<span class="sd">    optimizers</span>
<span class="sd">        A dictionary of optimizer names (choose from those in ``torch.optim``) and their hyperparameters for each</span>
<span class="sd">        model. Remember to change :meth:`_initial_values` and :meth:`_space` to optimize its hyperparameters.</span>
<span class="sd">    lr_schedulers</span>
<span class="sd">        A dictionary of lr scheduler names (choose from those in ``torch.optim.lr_scheduler``) and their</span>
<span class="sd">        hyperparameters for each model. Remember to change :meth:`_initial_values` and :meth:`_space` to optimize</span>
<span class="sd">        its hyperparameters.</span>
<span class="sd">    device</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AbstractModel.__init__">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.html#tabensemb.model.AbstractModel.__init__">[docs]</a>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">trainer</span><span class="p">:</span> <span class="n">Trainer</span><span class="p">,</span>
        <span class="n">program</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model_subset</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exclude_models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">store_in_harddisk</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">optimizers</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lr_schedulers</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        trainer:</span>
<span class="sd">            A :class:`~tabensemb.trainer.Trainer` instance that contains all information and datasets and will be</span>
<span class="sd">            linked to the model base. The trainer has loaded configs and data.</span>
<span class="sd">        program:</span>
<span class="sd">            The name of the model base. If None, the name from :meth:`_get_program_name` is used.</span>
<span class="sd">        model_subset:</span>
<span class="sd">            The names of models selected to be trained in the model base.</span>
<span class="sd">        exclude_models:</span>
<span class="sd">            The names of models that should not be trained. Only one of ``model_subset`` and ``exclude_models`` can</span>
<span class="sd">            be specified.</span>
<span class="sd">        store_in_harddisk:</span>
<span class="sd">            Whether to save models in the hard disk. If the global setting</span>
<span class="sd">            ``tabensemb.setting[&quot;low_memory&quot;]`` is True, True is used.</span>
<span class="sd">        optimizers</span>
<span class="sd">            A dictionary of optimizer names (choose from those in ``torch.optim``) and their hyperparameters for each</span>
<span class="sd">            model. Remember to change :meth:`_initial_values` and :meth:`_space` to optimize its hyperparameters.</span>
<span class="sd">        lr_schedulers</span>
<span class="sd">            A dictionary of lr scheduler names (choose from those in ``torch.optim.lr_scheduler``) and their</span>
<span class="sd">            hyperparameters for each model. Remember to change :meth:`_initial_values` and :meth:`_space` to optimize</span>
<span class="sd">            its hyperparameters.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Ignored.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">trainer</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s2">&quot;args&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;trainer.load_config is not called.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">leaderboard</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_subset</span> <span class="o">=</span> <span class="n">model_subset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exclude_models</span> <span class="o">=</span> <span class="n">exclude_models</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_subset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">exclude_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Only one of model_subset and exclude_models can be specified.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">store_in_harddisk</span> <span class="o">=</span> <span class="p">(</span>
            <span class="kc">True</span> <span class="k">if</span> <span class="n">tabensemb</span><span class="o">.</span><span class="n">setting</span><span class="p">[</span><span class="s2">&quot;low_memory&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="n">store_in_harddisk</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">program</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_program_name</span><span class="p">()</span> <span class="k">if</span> <span class="n">program</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">program</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">model_name</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;Adam&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">})</span>
            <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_model_names</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">optimizers</span> <span class="k">if</span> <span class="n">optimizers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedulers</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">model_name</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;StepLR&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;step_size&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>
            <span class="c1"># Actually doing nothing</span>
            <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_model_names</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedulers</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">lr_schedulers</span> <span class="k">if</span> <span class="n">lr_schedulers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{})</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">init_params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_losses</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">restored_epochs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_kwargs</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">init_params</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;trainer&quot;</span><span class="p">,</span> <span class="s2">&quot;self&quot;</span><span class="p">,</span> <span class="s2">&quot;frame&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_space</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mkdir</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_batch_size</span> <span class="o">=</span> <span class="mi">6</span></div>


<div class="viewcode-block" id="AbstractModel.save_kwargs">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.save_kwargs.html#tabensemb.model.AbstractModel.save_kwargs">[docs]</a>
    <span class="k">def</span> <span class="nf">save_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save all args and kwargs of the caller except for those in ``ignore``. It will trace back to the top caller that</span>
<span class="sd">        has the same method name and the same class of ``self`` as that of the current frame. For example, in nested</span>
<span class="sd">        __init__ calls of inherited classes, it will trace back to the first __init__ call and record kwargs layer by</span>
<span class="sd">        layer until it reaches the current caller.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        It will be automatically called in :meth:`__init__`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        d</span>
<span class="sd">            The dictionary to save params.</span>
<span class="sd">        ignore</span>
<span class="sd">            kwargs names to be ignored</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            The dictionary with the recorded kwargs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ignore</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">ignore</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">ignore</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">d</span>
        <span class="n">caller_frame</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">currentframe</span><span class="p">()</span><span class="o">.</span><span class="n">f_back</span>
        <span class="n">caller_function</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getframeinfo</span><span class="p">(</span><span class="n">caller_frame</span><span class="p">)</span><span class="o">.</span><span class="n">function</span>
        <span class="n">nest_init_params</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">while</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">caller_frame</span><span class="p">,</span> <span class="n">types</span><span class="o">.</span><span class="n">FrameType</span><span class="p">)</span>
            <span class="ow">and</span> <span class="s2">&quot;self&quot;</span> <span class="ow">in</span> <span class="n">caller_frame</span><span class="o">.</span><span class="n">f_locals</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">caller_frame</span><span class="o">.</span><span class="n">f_locals</span><span class="p">[</span><span class="s2">&quot;self&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)</span>
            <span class="ow">and</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getframeinfo</span><span class="p">(</span><span class="n">caller_frame</span><span class="p">)</span><span class="o">.</span><span class="n">function</span> <span class="o">==</span> <span class="n">caller_function</span>
        <span class="p">):</span>
            <span class="n">argvalues</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getargvalues</span><span class="p">(</span><span class="n">caller_frame</span><span class="p">)</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">key</span><span class="p">:</span> <span class="n">argvalues</span><span class="o">.</span><span class="n">locals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">argvalues</span><span class="o">.</span><span class="n">args</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ignore</span>
            <span class="p">}</span>
            <span class="n">nest_init_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">caller_frame</span> <span class="o">=</span> <span class="n">caller_frame</span><span class="o">.</span><span class="n">f_back</span>
        <span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">nest_init_params</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">d</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">d</span></div>


<div class="viewcode-block" id="AbstractModel.reset">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.reset.html#tabensemb.model.AbstractModel.reset">[docs]</a>
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reset the model base by calling __init__ with the recorded kwargs from :meth:`save_kwargs`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">trainer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">init_params</span><span class="p">)</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The device set in the linked :class:`~tabensemb.trainer.Trainer`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        str</span>
<span class="sd">            &quot;cpu&quot; or &quot;cuda&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">device</span>

<div class="viewcode-block" id="AbstractModel.fit">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.fit.html#tabensemb.model.AbstractModel.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">cont_feature_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">cat_feature_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">label_name</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">model_subset</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">derived_data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">warm_start</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">bayes_opt</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit all models using a tabular dataset.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The loaded dataset in the linked :class:`~tabensemb.trainer.Trainer` will be replaced.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        df:</span>
<span class="sd">            A tabular dataset.</span>
<span class="sd">        cont_feature_names:</span>
<span class="sd">            The names of continuous features.</span>
<span class="sd">        cat_feature_names:</span>
<span class="sd">            The names of categorical features.</span>
<span class="sd">        label_name:</span>
<span class="sd">            The names of targets.</span>
<span class="sd">        model_subset:</span>
<span class="sd">            The names of a subset of all available models (in :meth:`get_model_names`). Only these models will be</span>
<span class="sd">            trained.</span>
<span class="sd">        derived_data:</span>
<span class="sd">            Unstacked data derived from :meth:`tabensemb.data.datamodule.DataModule.derive_unstacked`. If None,</span>
<span class="sd">            unstacked data will be re-derived.</span>
<span class="sd">        verbose:</span>
<span class="sd">            Verbosity.</span>
<span class="sd">        warm_start:</span>
<span class="sd">            Finetune models based on previous trained models.</span>
<span class="sd">        bayes_opt:</span>
<span class="sd">            Whether to perform Gaussian-process-based Bayesian Hyperparameter Optimization for each model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">set_status</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">trainer_state</span> <span class="o">=</span> <span class="n">cp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">categories_inverse_transform</span><span class="p">(</span><span class="n">df</span><span class="p">),</span>
            <span class="n">cont_feature_names</span><span class="o">=</span><span class="n">cont_feature_names</span><span class="p">,</span>
            <span class="n">cat_feature_names</span><span class="o">=</span><span class="n">cat_feature_names</span><span class="p">,</span>
            <span class="n">label_name</span><span class="o">=</span><span class="n">label_name</span><span class="p">,</span>
            <span class="n">derived_data</span><span class="o">=</span><span class="n">derived_data</span><span class="p">,</span>
            <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trained</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">all_training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">bayes_opt</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s2">&quot;bayes_opt&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s2">&quot;bayes_opt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bayes_opt</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The argument bayes_opt of fit() conflicts with Trainer.bayes_opt. Use the former one.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
            <span class="n">dump_trainer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">model_subset</span><span class="o">=</span><span class="n">model_subset</span><span class="p">,</span>
            <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trained</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">load_state</span><span class="p">(</span><span class="n">trainer_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">set_status</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbstractModel.train">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.train.html#tabensemb.model.AbstractModel.train">[docs]</a>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">stderr_to_stdout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the model base using the dataset in the linked :class:`~tabensemb.trainer.Trainer` directly.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        *args:</span>
<span class="sd">            Arguments of :meth:`_train`.</span>
<span class="sd">        stderr_to_stdout:</span>
<span class="sd">            Redirect stderr to stdout. Useful for notebooks.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Arguments of :meth:`_train`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">set_status</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">verbose</span> <span class="o">=</span> <span class="s2">&quot;verbose&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">or</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">-------------Run </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="si">}</span><span class="s2">-------------</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">PlainText</span><span class="p">(</span><span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">stderr_to_stdout</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No model has been trained for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">-------------</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="si">}</span><span class="s2"> End-------------</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">set_status</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbstractModel.predict">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.predict.html#tabensemb.model.AbstractModel.predict">[docs]</a>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">derived_data</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ignore_absence</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">proba</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Make inferences on a new dataset using the selected model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        df:</span>
<span class="sd">            A new tabular dataset.</span>
<span class="sd">        model_name:</span>
<span class="sd">            A selected name of a model, which is already trained.</span>
<span class="sd">        model:</span>
<span class="sd">            The model returned by :meth:`_new_model`. If None, the model will be loaded from ``self.model``.</span>
<span class="sd">        derived_data:</span>
<span class="sd">            Unstacked data derived from :meth:`tabensemb.data.datamodule.DataModule.derive_unstacked`. If None,</span>
<span class="sd">            unstacked data will be re-derived.</span>
<span class="sd">        ignore_absence:</span>
<span class="sd">            Whether to ignore absent keys in ``derived_data``. Use True only when the model does not use derived_data.</span>
<span class="sd">        proba:</span>
<span class="sd">            Return probabilities instead of predicted classes for classification models.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Arguments of :meth:`_predict`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">            Predicted target. Always 2d np.ndarray.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">set_status</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Run fit() before predict().&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">model_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model_names</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> is not available. Select among </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">get_model_names</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">prepare_new_data</span><span class="p">(</span>
            <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">ignore_absence</span>
        <span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span>
            <span class="n">df</span><span class="p">,</span>
            <span class="n">model_name</span><span class="p">,</span>
            <span class="n">derived_data</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span> <span class="ow">or</span> <span class="n">proba</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">res</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">label_ordinal_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span>
                <span class="n">convert_proba_to_target</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">task</span><span class="p">)</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="AbstractModel.predict_proba">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.predict_proba.html#tabensemb.model.AbstractModel.predict_proba">[docs]</a>
    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict probabilities of each class.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        args</span>
<span class="sd">            Positional arguments of :meth:`predict`.</span>
<span class="sd">        kwargs</span>
<span class="sd">            Arguments of :meth:`predict`, except for ``proba``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">            For binary tasks, a (n_samples, 1) np.ndarray is returned as the probability of positive. For multiclass</span>
<span class="sd">            tasks, a (n_samples, n_classes) np.ndarray is returned.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Calling predict_proba on regression models.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;proba&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">del</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;proba&quot;</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">proba</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbstractModel.detach_model">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.detach_model.html#tabensemb.model.AbstractModel.detach_model">[docs]</a>
    <span class="k">def</span> <span class="nf">detach_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">program</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;AbstractModel&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Detach the chosen model to a separate model base with the same linked :class:`~tabensemb.trainer.Trainer`.</span>
<span class="sd">        If any model inside the model base is required, required models are detached as well. if any external model is</span>
<span class="sd">        required, the model should be detached through Trainer.detach_model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name:</span>
<span class="sd">            The name of the model to be detached.</span>
<span class="sd">        program:</span>
<span class="sd">            The new name of the detached model base. If the name is the same as the original one, the detached model is</span>
<span class="sd">            stored in memory to avoid overwriting the original model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        AbstractModel</span>
<span class="sd">            An AbstractModel containing the chosen model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">ModelDict</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The modelbase does not support model detaching.&quot;</span><span class="p">)</span>
        <span class="n">program</span> <span class="o">=</span> <span class="n">program</span> <span class="k">if</span> <span class="n">program</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">program</span>
        <span class="n">tmp_model</span> <span class="o">=</span> <span class="n">cp</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">tmp_model</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span>
        <span class="n">tmp_model</span><span class="o">.</span><span class="n">program</span> <span class="o">=</span> <span class="n">program</span>
        <span class="n">required_models</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">required_models</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
        <span class="n">required_models</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">x</span>
            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">required_models</span> <span class="k">if</span> <span class="n">required_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[])</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;EXTERN&quot;</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">tmp_model</span><span class="o">.</span><span class="n">model_subset</span> <span class="o">=</span> <span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">+</span> <span class="n">required_models</span>
        <span class="k">if</span> <span class="n">tmp_model</span><span class="o">.</span><span class="n">store_in_harddisk</span> <span class="ow">and</span> <span class="n">program</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">:</span>
            <span class="n">tmp_model</span><span class="o">.</span><span class="n">_mkdir</span><span class="p">()</span>
            <span class="n">tmp_model</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelDict</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">tmp_model</span><span class="o">.</span><span class="n">root</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tmp_model</span><span class="o">.</span><span class="n">store_in_harddisk</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">tmp_model</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">tmp_model</span><span class="o">.</span><span class="n">model_subset</span><span class="p">:</span>
            <span class="n">tmp_model</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">cp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">tmp_model</span><span class="o">.</span><span class="n">model_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">cp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_params</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">tmp_model</span></div>


<div class="viewcode-block" id="AbstractModel.set_path">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.set_path.html#tabensemb.model.AbstractModel.set_path">[docs]</a>
    <span class="k">def</span> <span class="nf">set_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">str</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the path of the model base (usually a trained one), including the paths of its models. It is used when</span>
<span class="sd">        migrating models to another directory.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path</span>
<span class="sd">            The path of the model base.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;root&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">path</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">store_in_harddisk</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">path</span>
                <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_path</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_path</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;.pkl&quot;</span></div>


<div class="viewcode-block" id="AbstractModel.new_model">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.new_model.html#tabensemb.model.AbstractModel.new_model">[docs]</a>
    <span class="k">def</span> <span class="nf">new_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A wrapper method to generate a new model while keeping the random seed constant.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name:</span>
<span class="sd">            The name of a selected model.</span>
<span class="sd">        verbose:</span>
<span class="sd">            Verbosity.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Parameters to generate the model. It contains all arguments in :meth:`_initial_values`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Any</span>
<span class="sd">            A new model (without any restriction to its type). It will be passed to :meth:`_train_single_model` and</span>
<span class="sd">            :meth:`_pred_single_model`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :meth:`_new_model`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">set_random_seed</span><span class="p">(</span><span class="n">tabensemb</span><span class="o">.</span><span class="n">setting</span><span class="p">[</span><span class="s2">&quot;random_seed&quot;</span><span class="p">])</span>
        <span class="n">required_models</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_required_models</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">required_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;required_models&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">required_models</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbstractModel.cal_feature_importance">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.cal_feature_importance.html#tabensemb.model.AbstractModel.cal_feature_importance">[docs]</a>
    <span class="k">def</span> <span class="nf">cal_feature_importance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">Iterable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate feature importance using a specified model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name</span>
<span class="sd">            The selected model in the model base.</span>
<span class="sd">        method</span>
<span class="sd">            The method to calculate importance. &quot;permutation&quot; or &quot;shap&quot;.</span>
<span class="sd">        indices</span>
<span class="sd">            The indices of data points where feature importance values are evaluated</span>
<span class="sd">        kwargs</span>
<span class="sd">            Arguments for :meth:`cal_shap`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">            Values of feature importance.</span>
<span class="sd">        list</span>
<span class="sd">            Corresponding feature names.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">datamodule</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span>
        <span class="n">all_feature_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">all_feature_names</span>
        <span class="n">label_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">label_name</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;permutation&quot;</span><span class="p">:</span>
            <span class="n">attr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">all_feature_names</span><span class="p">),))</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">test_indices</span> <span class="k">if</span> <span class="n">indices</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">indices</span>
            <span class="n">eval_data</span> <span class="o">=</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">indices</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">eval_derived_data</span> <span class="o">=</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">get_derived_data_slice</span><span class="p">(</span>
                <span class="n">datamodule</span><span class="o">.</span><span class="n">derived_data</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span>
            <span class="p">)</span>
            <span class="n">base_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                <span class="n">eval_data</span><span class="p">,</span>
                <span class="n">derived_data</span><span class="o">=</span><span class="n">eval_derived_data</span><span class="p">,</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">base_metric</span> <span class="o">=</span> <span class="n">metric_sklearn</span><span class="p">(</span>
                <span class="n">eval_data</span><span class="p">[</span><span class="n">label_name</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">base_pred</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_feature_names</span><span class="p">):</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">eval_data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">shuffled</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
                <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">shuffled</span><span class="p">)</span>
                <span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">shuffled</span>
                <span class="n">perm_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                    <span class="n">df</span><span class="p">,</span>
                    <span class="n">derived_data</span><span class="o">=</span><span class="n">datamodule</span><span class="o">.</span><span class="n">derive_unstacked</span><span class="p">(</span><span class="n">df</span><span class="p">),</span>
                    <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">attr</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span>
                    <span class="n">metric_sklearn</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">label_name</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">perm_pred</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span><span class="p">)</span>
                    <span class="o">-</span> <span class="n">base_metric</span>
                <span class="p">)</span>
            <span class="n">attr</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;shap&quot;</span><span class="p">:</span>
            <span class="n">attr</span> <span class="o">=</span> <span class="n">AbstractModel</span><span class="o">.</span><span class="n">cal_shap</span><span class="p">(</span>
                <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
        <span class="n">importance_names</span> <span class="o">=</span> <span class="n">cp</span><span class="p">(</span><span class="n">all_feature_names</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">attr</span><span class="p">,</span> <span class="n">importance_names</span></div>


<div class="viewcode-block" id="AbstractModel.cal_shap">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.cal_shap.html#tabensemb.model.AbstractModel.cal_shap">[docs]</a>
    <span class="k">def</span> <span class="nf">cal_shap</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">return_importance</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">n_background</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">explainer</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;KernelExplainer&quot;</span><span class="p">,</span>
        <span class="n">init_kwargs</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">call_kwargs</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">:</span> <span class="n">Iterable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate SHAP values using a specified model. ``shap.kmeans`` is called to summarize the training data as the</span>
<span class="sd">        background data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name</span>
<span class="sd">            The selected model in the model base.</span>
<span class="sd">        return_importance</span>
<span class="sd">            True to return mean absolute SHAP values. False to return ``shap.Explainer``, ``shap.Explanation``,</span>
<span class="sd">             and results of :meth:``shap.Explainer.shap_values``</span>
<span class="sd">        n_background</span>
<span class="sd">            Number of background data passed to ``shap.Explainer`` as ``data``.</span>
<span class="sd">        indices</span>
<span class="sd">            The indices of data points where shap values are evaluated</span>
<span class="sd">        explainer</span>
<span class="sd">            The name of an explainer available at shap.</span>
<span class="sd">        init_kwargs</span>
<span class="sd">            Arguments of ``explainer.__init__``</span>
<span class="sd">        call_kwargs</span>
<span class="sd">            Arguments of ``explainer.__call__`</span>
<span class="sd">        kwargs</span>
<span class="sd">            Ignored.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        attr</span>
<span class="sd">            The SHAP values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">shap</span>

        <span class="n">trainer_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">df</span>
        <span class="n">train_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train_indices</span>
        <span class="n">test_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">test_indices</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">test_indices</span> <span class="k">if</span> <span class="n">indices</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">indices</span>
        <span class="n">all_feature_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">all_feature_names</span>
        <span class="n">datamodule</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span>
        <span class="n">background_data</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">kmeans</span><span class="p">(</span>
            <span class="n">trainer_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train_indices</span><span class="p">,</span> <span class="n">all_feature_names</span><span class="p">],</span> <span class="n">n_background</span>
        <span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span>
            <span class="s2">&quot;ignore&quot;</span><span class="p">,</span>
            <span class="n">message</span><span class="o">=</span><span class="s2">&quot;The default of &#39;normalize&#39; will be set to False in version 1.2 and deprecated in version 1.4.&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">all_feature_names</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                <span class="n">df</span><span class="p">,</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                <span class="n">derived_data</span><span class="o">=</span><span class="n">datamodule</span><span class="o">.</span><span class="n">derive_unstacked</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">categorical_only</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">ignore_absence</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

        <span class="n">func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">_predict_with_ndarray</span><span class="p">,</span>
            <span class="n">all_feature_names</span><span class="o">=</span><span class="n">all_feature_names</span><span class="p">,</span>
            <span class="n">modelbase</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">datamodule</span><span class="o">=</span><span class="n">datamodule</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># test_indices = np.random.choice(test_indices, size=10, replace=False)</span>
        <span class="n">test_data</span> <span class="o">=</span> <span class="n">trainer_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">indices</span><span class="p">,</span> <span class="n">all_feature_names</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">explainer_cls</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">shap</span><span class="p">,</span> <span class="n">explainer</span><span class="p">)</span>
        <span class="n">args</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">explainer_cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">))</span>
        <span class="n">init_kwargs_</span> <span class="o">=</span> <span class="n">update_defaults_by_kwargs</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="p">{</span><span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">background_data</span><span class="p">}</span>
                <span class="k">if</span> <span class="s2">&quot;data&quot;</span> <span class="ow">in</span> <span class="n">args</span>
                <span class="k">else</span> <span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;masker&quot;</span><span class="p">:</span> <span class="n">shap</span><span class="o">.</span><span class="n">maskers</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span>
                            <span class="n">trainer_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train_indices</span><span class="p">,</span> <span class="n">all_feature_names</span><span class="p">]</span>
                        <span class="p">)</span>
                    <span class="p">}</span>
                    <span class="k">if</span> <span class="s2">&quot;masker&quot;</span> <span class="ow">in</span> <span class="n">args</span>
                    <span class="k">else</span> <span class="nb">dict</span><span class="p">()</span>
                <span class="p">)</span>
            <span class="p">),</span>
            <span class="n">init_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initializing </span><span class="si">{</span><span class="n">explainer</span><span class="si">}</span><span class="s2"> with </span><span class="si">{</span><span class="n">init_kwargs_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">call_kwargs_</span> <span class="o">=</span> <span class="n">update_defaults_by_kwargs</span><span class="p">(</span><span class="nb">dict</span><span class="p">(),</span> <span class="n">call_kwargs</span><span class="p">)</span>
        <span class="n">explainer_</span> <span class="o">=</span> <span class="n">explainer_cls</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="o">**</span><span class="n">init_kwargs_</span><span class="p">)</span>
        <span class="n">explanation</span> <span class="o">=</span> <span class="n">explainer_</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="o">**</span><span class="n">call_kwargs_</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explanation</span><span class="o">.</span><span class="n">values</span>
        <span class="n">attr</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)]</span>
                <span class="o">+</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">shap_values</span><span class="p">[</span><span class="mi">1</span><span class="p">:]],</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
            <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">attr</span> <span class="k">if</span> <span class="n">return_importance</span> <span class="k">else</span> <span class="p">(</span><span class="n">explainer_</span><span class="p">,</span> <span class="n">explanation</span><span class="p">,</span> <span class="n">shap_values</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbstractModel._check_params">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._check_params.html#tabensemb.model.AbstractModel._check_params">[docs]</a>
    <span class="k">def</span> <span class="nf">_check_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check the validity of hyperparameters. This is implemented originally for batch_size because TabNet crashes</span>
<span class="sd">        when batch_size is small under certain situations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name</span>
<span class="sd">            The name of a selected model.</span>
<span class="sd">        kwargs</span>
<span class="sd">            Parameters to generate the model. It contains all arguments in :meth:`_initial_values`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            The checked kwargs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;batch_size&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;original_batch_size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_size</span>
            <span class="n">n_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train_indices</span><span class="p">)</span>
            <span class="n">limit_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_batch_size</span>
            <span class="k">if</span> <span class="n">limit_batch_size</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="n">n_train</span> <span class="o">%</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="mi">4</span> <span class="ow">or</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">:</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Using batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2"> and len(training set)=</span><span class="si">{</span><span class="n">n_train</span><span class="si">}</span><span class="s2">, which will make the mini &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;batch extremely small. A very small batch may cause unexpected numerical issue, especially &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;for TabNet. However, the attribute `limit_batch_size` is set to -1.&quot;</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="n">n_train</span> <span class="o">%</span> <span class="n">batch_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Using batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2"> and len(training set)=</span><span class="si">{</span><span class="n">n_train</span><span class="si">}</span><span class="s2">, which will make the &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;mini batch illegal. However, the attribute `limit_batch_size` is set to -1.&quot;</span>
                    <span class="p">)</span>
            <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="o">&lt;</span> <span class="n">limit_batch_size</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;limit_batch_size=</span><span class="si">{</span><span class="n">limit_batch_size</span><span class="si">}</span><span class="s2"> is illegal. Use limit_batch_size=2 instead.&quot;</span>
                <span class="p">)</span>
                <span class="n">limit_batch_size</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="n">new_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
            <span class="k">if</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;TabNet&quot;</span><span class="p">:</span>
                <span class="n">_new_batch_size</span> <span class="o">=</span> <span class="mi">64</span>
                <span class="k">if</span> <span class="n">new_batch_size</span> <span class="o">&lt;</span> <span class="n">_new_batch_size</span><span class="p">:</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;For TabNet, using small batch_size (</span><span class="si">{</span><span class="n">new_batch_size</span><span class="si">}</span><span class="s2">) may trigger CUDA device-side assert. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Using batch_size=</span><span class="si">{</span><span class="n">_new_batch_size</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
                    <span class="p">)</span>
                    <span class="n">new_batch_size</span> <span class="o">=</span> <span class="n">_new_batch_size</span>
            <span class="k">if</span> <span class="n">new_batch_size</span> <span class="o">&lt;</span> <span class="n">limit_batch_size</span><span class="p">:</span>
                <span class="n">new_batch_size</span> <span class="o">=</span> <span class="n">limit_batch_size</span>
            <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">n_train</span> <span class="o">%</span> <span class="n">new_batch_size</span> <span class="o">&lt;</span> <span class="n">limit_batch_size</span><span class="p">:</span>
                <span class="n">_new_batch_size</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_train</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_train</span> <span class="o">//</span> <span class="n">new_batch_size</span><span class="p">)))</span>
                    <span class="k">if</span> <span class="n">n_train</span> <span class="o">&gt;=</span> <span class="n">limit_batch_size</span>
                    <span class="k">else</span> <span class="n">n_train</span>
                <span class="p">)</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Using batch_size=</span><span class="si">{</span><span class="n">new_batch_size</span><span class="si">}</span><span class="s2"> and len(training set)=</span><span class="si">{</span><span class="n">n_train</span><span class="si">}</span><span class="s2">, which will make the mini batch &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;smaller than limit_batch_size=</span><span class="si">{</span><span class="n">limit_batch_size</span><span class="si">}</span><span class="s2">. Using batch_size=</span><span class="si">{</span><span class="n">_new_batch_size</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
                <span class="p">)</span>
                <span class="n">new_batch_size</span> <span class="o">=</span> <span class="n">_new_batch_size</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_batch_size</span>
        <span class="k">return</span> <span class="n">kwargs</span></div>


<div class="viewcode-block" id="AbstractModel._get_required_models">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._get_required_models.html#tabensemb.model.AbstractModel._get_required_models">[docs]</a>
    <span class="k">def</span> <span class="nf">_get_required_models</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Extract models specified in :meth:`required_models`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name</span>
<span class="sd">            The name of the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict or None</span>
<span class="sd">            A dictionary of extracted models required by the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">required_model_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">required_models</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">required_model_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">required_models</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">required_model_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="n">model_name</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> is required by itself.&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_model_names</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is required for model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">, but is not trained.&quot;</span>
                        <span class="p">)</span>
                    <span class="n">required_models</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
                <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;EXTERN_&quot;</span><span class="p">):</span>
                    <span class="n">spl</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">spl</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">spl</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span> <span class="ow">and</span> <span class="n">spl</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;WRAP&quot;</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Unrecognized required model name </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> from external model bases.&quot;</span>
                        <span class="p">)</span>
                    <span class="n">program</span><span class="p">,</span> <span class="n">ext_model_name</span> <span class="o">=</span> <span class="n">spl</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">spl</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                    <span class="n">wrap</span> <span class="o">=</span> <span class="n">spl</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;WRAP&quot;</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">modelbase</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get_modelbase</span><span class="p">(</span><span class="n">program</span><span class="o">=</span><span class="n">program</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Model base </span><span class="si">{</span><span class="n">program</span><span class="si">}</span><span class="s2"> is required for model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">, but does not exist.&quot;</span>
                            <span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Model base </span><span class="si">{</span><span class="n">program</span><span class="si">}</span><span class="s2"> is required for model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">, but does not exist. It is &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;mainly caused by model detaching with Trainer.detach_modelbase. Please use &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;Trainer.detach_model instead.&quot;</span>
                            <span class="p">)</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">detached_model</span> <span class="o">=</span> <span class="n">modelbase</span><span class="o">.</span><span class="n">detach_model</span><span class="p">(</span>
                            <span class="n">model_name</span><span class="o">=</span><span class="n">ext_model_name</span>
                        <span class="p">)</span>
                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">ext_model_name</span><span class="si">}</span><span class="s2"> can not be detached from model base </span><span class="si">{</span><span class="n">program</span><span class="si">}</span><span class="s2">. Exception:</span><span class="se">\n</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                    <span class="k">if</span> <span class="n">wrap</span><span class="p">:</span>
                        <span class="kn">from</span> <span class="nn">.pytorch_tabular</span> <span class="kn">import</span> <span class="p">(</span>
                            <span class="n">PytorchTabular</span><span class="p">,</span>
                            <span class="n">PytorchTabularWrapper</span><span class="p">,</span>
                        <span class="p">)</span>
                        <span class="kn">from</span> <span class="nn">.widedeep</span> <span class="kn">import</span> <span class="n">WideDeep</span><span class="p">,</span> <span class="n">WideDeepWrapper</span>

                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">detached_model</span><span class="p">,</span> <span class="n">PytorchTabular</span><span class="p">):</span>
                            <span class="n">detached_model</span> <span class="o">=</span> <span class="n">PytorchTabularWrapper</span><span class="p">(</span><span class="n">detached_model</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">detached_model</span><span class="p">,</span> <span class="n">WideDeep</span><span class="p">):</span>
                            <span class="n">detached_model</span> <span class="o">=</span> <span class="n">WideDeepWrapper</span><span class="p">(</span><span class="n">detached_model</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">detached_model</span><span class="p">,</span> <span class="n">TorchModel</span><span class="p">):</span>
                            <span class="n">detached_model</span> <span class="o">=</span> <span class="n">TorchModelWrapper</span><span class="p">(</span><span class="n">detached_model</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">detached_model</span><span class="p">)</span><span class="si">}</span><span class="s2"> does not support wrapping. Supported model bases &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;are PytorchTabular, WideDeep, and TorchModels.&quot;</span>
                            <span class="p">)</span>
                    <span class="n">required_models</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">detached_model</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Unrecognized model name </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> required by </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
            <span class="k">return</span> <span class="n">required_models</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="AbstractModel.required_models">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.required_models.html#tabensemb.model.AbstractModel.required_models">[docs]</a>
    <span class="k">def</span> <span class="nf">required_models</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The names of models required by the requested model. If not None and the required model is</span>
<span class="sd">        trained, the required model will be passed to :meth:`_new_model`.</span>
<span class="sd">        If models from other model bases are required, the name should be</span>
<span class="sd">        ``EXTERN_{Name of the model base}_{Name of the model}``</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        For :class:`TorchModel`, if the required model is in the :class:`TorchModel` itself, the</span>
<span class="sd">        :class:`.AbstractNN` is passed to :meth:`_new_model`; if the required model is in another model base, the</span>
<span class="sd">        :class:`.AbstractModel` is passed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="AbstractModel.inspect_attr">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.inspect_attr.html#tabensemb.model.AbstractModel.inspect_attr">[docs]</a>
    <span class="k">def</span> <span class="nf">inspect_attr</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">attributes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">df</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">derived_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">to_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get attributes of the model after evaluating the model on training, validation, and testing sets respectively.</span>
<span class="sd">        If ``df`` is given, values after evaluating the given set are returned.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name</span>
<span class="sd">            The name of the inspected model.</span>
<span class="sd">        attributes</span>
<span class="sd">            The requested attributes. If the model does not have the attribute, None is returned.</span>
<span class="sd">        df</span>
<span class="sd">            The tabular dataset.</span>
<span class="sd">        derived_data:</span>
<span class="sd">            Unstacked data derived from :meth:`tabensemb.data.datamodule.DataModule.derive_unstacked`. If None,</span>
<span class="sd">            unstacked data will be re-derived.</span>
<span class="sd">        to_numpy</span>
<span class="sd">            If True, call ``numpy()`` if the attribute is a torch.Tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            A dict with keys ``train``, ``val``, and ``test`` if ``df`` is not given, and each value contains</span>
<span class="sd">            the attributes requested. If ``df`` is given, a dict with a single key ``USER_INPUT`` and the corresponding</span>
<span class="sd">            value contains the attributes. The prediction is also included with the key ``prediction``.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">to_cpu</span><span class="p">(</span><span class="n">attr</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
                <span class="n">attr</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">attr</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">to_numpy</span><span class="p">:</span>
                    <span class="n">attr</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">attr</span>

        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">df</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inspect_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">part</span><span class="p">:</span> <span class="p">{}</span> <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">]}</span>
            <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">part</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">D_train</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">),</span>
                <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_val</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">D_val</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">),</span>
                <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">D_test</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">),</span>
            <span class="p">]:</span>
                <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span>
                    <span class="n">X</span><span class="p">,</span> <span class="n">derived_data</span><span class="o">=</span><span class="n">D</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">attributes</span><span class="p">:</span>
                    <span class="n">inspect_dict</span><span class="p">[</span><span class="n">part</span><span class="p">][</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_cpu</span><span class="p">(</span><span class="n">cp</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="kc">None</span><span class="p">)))</span>
                <span class="n">inspect_dict</span><span class="p">[</span><span class="n">part</span><span class="p">][</span><span class="s2">&quot;prediction&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inspect_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;USER_INPUT&quot;</span><span class="p">:</span> <span class="p">{}}</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                <span class="n">df</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">derived_data</span><span class="o">=</span><span class="n">derived_data</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">attributes</span><span class="p">:</span>
                <span class="n">inspect_dict</span><span class="p">[</span><span class="s2">&quot;USER_INPUT&quot;</span><span class="p">][</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_cpu</span><span class="p">(</span>
                    <span class="n">cp</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
                <span class="p">)</span>
            <span class="n">inspect_dict</span><span class="p">[</span><span class="s2">&quot;USER_INPUT&quot;</span><span class="p">][</span><span class="s2">&quot;prediction&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span>
        <span class="k">return</span> <span class="n">inspect_dict</span></div>


<div class="viewcode-block" id="AbstractModel._predict_all">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._predict_all.html#tabensemb.model.AbstractModel._predict_all">[docs]</a>
    <span class="k">def</span> <span class="nf">_predict_all</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">test_data_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Make inferences on training/validation/testing datasets to evaluate the performance of all models.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        verbose:</span>
<span class="sd">            Verbosity.</span>
<span class="sd">        test_data_only:</span>
<span class="sd">            Whether to predict only the testing set. If True, the whole dataset will be evaluated.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            A dict of results. Its keys are names of models, and its values are results from :meth:`_predict_model` for</span>
<span class="sd">            each model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">set_status</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_train_status</span><span class="p">()</span>
        <span class="n">model_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model_names</span><span class="p">()</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">tc</span> <span class="o">=</span> <span class="n">TqdmController</span><span class="p">()</span>
        <span class="n">tc</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model_names</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">idx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">model_names</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">predictions</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_model</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">test_data_only</span><span class="o">=</span><span class="n">test_data_only</span>
            <span class="p">)</span>
        <span class="n">tc</span><span class="o">.</span><span class="n">enable_tqdm</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">predictions</span></div>


<div class="viewcode-block" id="AbstractModel._predict_model_on_partition">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._predict_model_on_partition.html#tabensemb.model.AbstractModel._predict_model_on_partition">[docs]</a>
    <span class="k">def</span> <span class="nf">_predict_model_on_partition</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">partition</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get predictions of a model on the selected partition.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name</span>
<span class="sd">            The selected model.</span>
<span class="sd">        partition</span>
<span class="sd">            &quot;train&quot;, &quot;val&quot;, or &quot;test&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">D_train</span><span class="p">),</span>
            <span class="s2">&quot;val&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_val</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">D_val</span><span class="p">),</span>
            <span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">D_test</span><span class="p">),</span>
            <span class="s2">&quot;all&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">df</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">derived_data</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span>
            <span class="n">d</span><span class="p">[</span><span class="n">partition</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">derived_data</span><span class="o">=</span><span class="n">d</span><span class="p">[</span><span class="n">partition</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="AbstractModel._predict_model">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._predict_model.html#tabensemb.model.AbstractModel._predict_model">[docs]</a>
    <span class="k">def</span> <span class="nf">_predict_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">test_data_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get predictions of a model on all partitions.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name</span>
<span class="sd">            The selected model.</span>
<span class="sd">        test_data_only:</span>
<span class="sd">            Whether to predict only the testing set. If True, the whole dataset will be evaluated.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Its keys are &quot;Training&quot;, &quot;Testing&quot;, and &quot;Validation&quot;. Its values are tuples containing predicted values and</span>
<span class="sd">        ground truth values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">test_data_only</span><span class="p">:</span>
            <span class="n">y_train_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_model_on_partition</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">partition</span><span class="o">=</span><span class="s2">&quot;train&quot;</span>
            <span class="p">)</span>
            <span class="n">y_val_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_model_on_partition</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">partition</span><span class="o">=</span><span class="s2">&quot;val&quot;</span>
            <span class="p">)</span>
            <span class="n">y_train</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train</span>
            <span class="n">y_val</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y_val</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">y_train</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">y_val_pred</span> <span class="o">=</span> <span class="n">y_val</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">y_test_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_model_on_partition</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">partition</span><span class="o">=</span><span class="s2">&quot;test&quot;</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;Training&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">y_train_pred</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span>
            <span class="s2">&quot;Testing&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">y_test_pred</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span><span class="p">),</span>
            <span class="s2">&quot;Validation&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">y_val_pred</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span>
        <span class="p">}</span></div>


<div class="viewcode-block" id="AbstractModel._predict">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._predict.html#tabensemb.model.AbstractModel._predict">[docs]</a>
    <span class="k">def</span> <span class="nf">_predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">derived_data</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Make prediction based on a tabular dataset using the selected model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        df:</span>
<span class="sd">            A new tabular dataset that has the same structure as ``self.trainer.datamodule.X_test``.</span>
<span class="sd">        model_name:</span>
<span class="sd">            A name of a selected model, which is already trained. It is used to process the input data if any specific</span>
<span class="sd">            routine is defined for this model in :meth:`~AbstractModel._data_preprocess`.</span>
<span class="sd">        derived_data:</span>
<span class="sd">            Unstacked data derived from :meth:`tabensemb.data.datamodule.DataModule.derive_unstacked` that has the</span>
<span class="sd">            same structure as ``self.trainer.datamodule.D_test``.</span>
<span class="sd">        model:</span>
<span class="sd">            The model returned by :meth:`_new_model`. If None, the model will be loaded from ``self.model``.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Ignored.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">            Prediction of the target.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">set_status</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_preprocess</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pred_single_model</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">model</span><span class="p">,</span>
            <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="AbstractModel._custom_training_params">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._custom_training_params.html#tabensemb.model.AbstractModel._custom_training_params">[docs]</a>
    <span class="k">def</span> <span class="nf">_custom_training_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Customized training settings to override settings in the configuration. The configuration will be restored after</span>
<span class="sd">        training the model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name</span>
<span class="sd">            The name of a selected model</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            A dict of training parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{}</span></div>


<div class="viewcode-block" id="AbstractModel._train">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._train.html#tabensemb.model.AbstractModel._train">[docs]</a>
    <span class="k">def</span> <span class="nf">_train</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_subset</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dump_trainer</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">warm_start</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The basic framework of training models, including processing the dataset, training each model (with/without</span>
<span class="sd">        bayesian hyperparameter optimization), and evaluating them on the dataset.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_subset:</span>
<span class="sd">            The names of a subset of all available models (in :func:`get_model_names`). Only these models will be</span>
<span class="sd">            trained.</span>
<span class="sd">        dump_trainer:</span>
<span class="sd">            Whether to save the trainer after models are trained.</span>
<span class="sd">        verbose:</span>
<span class="sd">            Verbosity.</span>
<span class="sd">        warm_start:</span>
<span class="sd">            Finetune models based on previous trained models.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Ignored.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">set_status</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">store_in_harddisk</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelDict</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">get_model_names</span><span class="p">()</span> <span class="k">if</span> <span class="n">model_subset</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">model_subset</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_data_preprocess</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span><span class="p">)</span>
            <span class="n">tmp_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_params</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
            <span class="n">space</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_space</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>

            <span class="n">original_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">args</span>
            <span class="n">args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">args</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_custom_training_params</span><span class="p">(</span><span class="n">model_name</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>

            <span class="n">do_bayes_opt</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;bayes_opt&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">warm_start</span>
            <span class="n">total_epoch</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">tabensemb</span><span class="o">.</span><span class="n">setting</span><span class="p">[</span><span class="s2">&quot;debug_mode&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="mi">2</span>
            <span class="k">if</span> <span class="n">do_bayes_opt</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">space</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">min_calls</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">space</span><span class="p">)</span>
                <span class="n">bayes_calls</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="nb">max</span><span class="p">([</span><span class="n">args</span><span class="p">[</span><span class="s2">&quot;bayes_calls&quot;</span><span class="p">],</span> <span class="n">min_calls</span><span class="p">])</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">tabensemb</span><span class="o">.</span><span class="n">setting</span><span class="p">[</span><span class="s2">&quot;debug_mode&quot;</span><span class="p">]</span>
                    <span class="k">else</span> <span class="n">min_calls</span>
                <span class="p">)</span>
                <span class="n">callback</span> <span class="o">=</span> <span class="n">BayesCallback</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">bayes_calls</span><span class="p">)</span>
                <span class="k">global</span> <span class="n">_bayes_objective</span>

                <span class="nd">@skopt</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">use_named_args</span><span class="p">(</span><span class="n">space</span><span class="p">)</span>
                <span class="k">def</span> <span class="nf">_bayes_objective</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">):</span>
                    <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="k">with</span> <span class="n">HiddenPrints</span><span class="p">():</span>
                            <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_model</span><span class="p">(</span>
                                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span>
                            <span class="p">)</span>

                            <span class="bp">self</span><span class="o">.</span><span class="n">_train_single_model</span><span class="p">(</span>
                                <span class="n">model</span><span class="p">,</span>
                                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                                <span class="n">epoch</span><span class="o">=</span><span class="p">(</span>
                                    <span class="n">args</span><span class="p">[</span><span class="s2">&quot;bayes_epoch&quot;</span><span class="p">]</span>
                                    <span class="k">if</span> <span class="ow">not</span> <span class="n">tabensemb</span><span class="o">.</span><span class="n">setting</span><span class="p">[</span><span class="s2">&quot;debug_mode&quot;</span><span class="p">]</span>
                                    <span class="k">else</span> <span class="mi">1</span>
                                <span class="p">),</span>
                                <span class="n">X_train</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;X_train&quot;</span><span class="p">],</span>
                                <span class="n">y_train</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;y_train&quot;</span><span class="p">],</span>
                                <span class="n">X_val</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;X_val&quot;</span><span class="p">],</span>
                                <span class="n">y_val</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;y_val&quot;</span><span class="p">],</span>
                                <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                <span class="n">in_bayes_opt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                <span class="o">**</span><span class="n">params</span><span class="p">,</span>
                            <span class="p">)</span>

                        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bayes_eval</span><span class="p">(</span>
                            <span class="n">model</span><span class="p">,</span>
                            <span class="n">data</span><span class="p">[</span><span class="s2">&quot;X_train&quot;</span><span class="p">],</span>
                            <span class="n">data</span><span class="p">[</span><span class="s2">&quot;y_train&quot;</span><span class="p">],</span>
                            <span class="n">data</span><span class="p">[</span><span class="s2">&quot;X_val&quot;</span><span class="p">],</span>
                            <span class="n">data</span><span class="p">[</span><span class="s2">&quot;y_val&quot;</span><span class="p">],</span>
                        <span class="p">)</span>
                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="n">joint_trackback</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                            <span class="n">traceback</span><span class="o">.</span><span class="n">format_exception</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>
                        <span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;An exception occurs when evaluating a bayes call:&quot;</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="n">joint_trackback</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;with the following parameters:&quot;</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
                        <span class="k">if</span> <span class="p">(</span>
                            <span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;TabNet&quot;</span>
                            <span class="ow">and</span> <span class="s2">&quot;CUDA error: device-side assert triggered&quot;</span>
                            <span class="ow">in</span> <span class="n">joint_trackback</span>
                        <span class="p">):</span>
                            <span class="nb">print</span><span class="p">(</span>
                                <span class="s2">&quot;You are using TabNet and a CUDA device-side assert is triggered. You encountered</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="s2">&quot;the same issue as I did. For TabNet, it is really weird that if a batch is extremely</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="s2">&quot;small (less than 5 maybe), during back-propagation, the gradient of its embedding</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="s2">&quot;may contain NaN, which, in the next step, causes CUDA device-side assert in</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="s2">&quot;sparsemax. See these two issues:</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="s2">&quot;https://github.com/dreamquark-ai/tabnet/issues/135</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="s2">&quot;https://github.com/dreamquark-ai/tabnet/issues/432</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="p">)</span>
                        <span class="k">if</span> <span class="p">(</span>
                            <span class="s2">&quot;CUDA error: device-side assert triggered&quot;</span>
                            <span class="ow">in</span> <span class="n">joint_trackback</span>
                        <span class="p">):</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                                <span class="s2">&quot;A CUDA device-side assert is triggered. Unfortunately, CUDA device-side assert will</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="s2">&quot;make the entire GPU session not accessible, the whole hyperparameter optimization</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="s2">&quot;process invalid, and the final model training raising an exception. The error is</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="s2">&quot;just re-raised because currently there is no way to restart the GPU session and</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="s2">&quot;continue the HPO process. Please tell me if there is a solution.&quot;</span>
                            <span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Returning a large value instead.&quot;</span><span class="p">)</span>
                        <span class="n">res</span> <span class="o">=</span> <span class="mi">100</span>
                    <span class="c1"># If a result from one bayes opt iteration is very large (over 10000) caused by instability of the</span>
                    <span class="c1"># model, it can not be fully reproduced during another execution and has error (though small, it</span>
                    <span class="c1"># disturbs bayes optimization).</span>
                    <span class="n">limit</span> <span class="o">=</span> <span class="n">tabensemb</span><span class="o">.</span><span class="n">setting</span><span class="p">[</span><span class="s2">&quot;bayes_loss_limit&quot;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">res</span> <span class="o">&gt;</span> <span class="n">limit</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;The loss value (</span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="s2">) is greater than </span><span class="si">{</span><span class="n">limit</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">limit</span><span class="si">}</span><span class="s2"> will be returned. Consider &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;debugging such instability of the model, or check whether the loss value is normalized by &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;the number of samples. The limitation bayes_loss_limit can be changed in the global &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;setting.&quot;</span>
                        <span class="p">)</span>
                        <span class="k">return</span> <span class="n">limit</span>
                    <span class="c1"># To guarantee reproducibility on different machines.</span>
                    <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

                <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
                    <span class="c1"># To obtain clean progress bar.</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span>
                        <span class="s2">&quot;ignore&quot;</span><span class="p">,</span>
                        <span class="n">message</span><span class="o">=</span><span class="s2">&quot;The objective has been evaluated at this point before&quot;</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span>
                        <span class="s2">&quot;ignore&quot;</span><span class="p">,</span>
                        <span class="n">message</span><span class="o">=</span><span class="s2">&quot;`pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be removed in v1.10.0.&quot;</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="s2">&quot;batch_size&quot;</span> <span class="ow">in</span> <span class="n">tmp_params</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                        <span class="ow">and</span> <span class="s2">&quot;original_batch_size&quot;</span> <span class="ow">in</span> <span class="n">tmp_params</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                    <span class="p">):</span>
                        <span class="n">tmp_params</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_params</span><span class="p">[</span><span class="s2">&quot;original_batch_size&quot;</span><span class="p">]</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="n">gp_minimize</span><span class="p">(</span>
                        <span class="n">_bayes_objective</span><span class="p">,</span>
                        <span class="n">space</span><span class="p">,</span>
                        <span class="n">n_calls</span><span class="o">=</span><span class="n">bayes_calls</span><span class="p">,</span>
                        <span class="n">n_initial_points</span><span class="o">=</span><span class="p">(</span>
                            <span class="mi">10</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">tabensemb</span><span class="o">.</span><span class="n">setting</span><span class="p">[</span><span class="s2">&quot;debug_mode&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="mi">0</span>
                        <span class="p">),</span>
                        <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="o">.</span><span class="n">call</span><span class="p">,</span>
                        <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">x0</span><span class="o">=</span><span class="p">[</span><span class="n">tmp_params</span><span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">space</span><span class="p">],</span>
                    <span class="p">)</span>
                <span class="n">opt_params</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">val</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span><span class="p">)}</span>
                <span class="n">params</span> <span class="o">=</span> <span class="n">tmp_params</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">opt_params</span><span class="p">)</span>
                <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_params</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">cp</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
                <span class="n">callback</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                <span class="n">skopt</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span>
                    <span class="n">result</span><span class="p">,</span>
                    <span class="n">add_postfix</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_skopt.pt&quot;</span><span class="p">)),</span>
                    <span class="n">store_objective</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">tmp_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_params</span><span class="p">(</span>
                    <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span>
                <span class="p">)</span>  <span class="c1"># to announce the optimized params.</span>
            <span class="k">elif</span> <span class="n">do_bayes_opt</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">space</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;No hyperparameter space defined for model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

            <span class="n">tmp_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="o">**</span><span class="n">tmp_params</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">warm_start</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="n">warm_start</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trained</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_support_warm_start</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="n">warm_start</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_support_warm_start</span><span class="p">:</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> does not support warm_start.&quot;</span>
                    <span class="p">)</span>
                <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_model</span><span class="p">(</span>
                    <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="o">**</span><span class="n">tmp_params</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_train_single_model</span><span class="p">(</span>
                <span class="n">model</span><span class="p">,</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                <span class="n">epoch</span><span class="o">=</span><span class="n">total_epoch</span><span class="p">,</span>
                <span class="n">X_train</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;X_train&quot;</span><span class="p">],</span>
                <span class="n">y_train</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;y_train&quot;</span><span class="p">],</span>
                <span class="n">X_val</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;X_val&quot;</span><span class="p">],</span>
                <span class="n">y_val</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;y_val&quot;</span><span class="p">],</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span><span class="p">,</span>
                <span class="n">in_bayes_opt</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="o">**</span><span class="n">tmp_params</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">def</span> <span class="nf">pred_set</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pred_single_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">metric</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_metric_sklearn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s2"> loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">pred_set</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;X_train&quot;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;y_train&quot;</span><span class="p">],</span> <span class="s2">&quot;Training&quot;</span><span class="p">)</span>
            <span class="n">pred_set</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;X_val&quot;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;y_val&quot;</span><span class="p">],</span> <span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
            <span class="n">pred_set</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;X_test&quot;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">],</span> <span class="s2">&quot;Testing&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">original_args</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">set_status</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dump_trainer</span><span class="p">:</span>
            <span class="n">save_trainer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbstractModel._default_metric_sklearn">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._default_metric_sklearn.html#tabensemb.model.AbstractModel._default_metric_sklearn">[docs]</a>
    <span class="k">def</span> <span class="nf">_default_metric_sklearn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate MSE loss for regression tasks and log loss for classification tasks using sklearn APIs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y_true</span>
<span class="sd">            Ground truth values.</span>
<span class="sd">        y_pred</span>
<span class="sd">            Predicted values.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        str</span>
<span class="sd">            &quot;mse&quot; for regression tasks and &quot;log_loss&quot; for classification tasks.</span>
<span class="sd">        float</span>
<span class="sd">            MSE loss for regression tasks and log loss for classification tasks</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">task</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">task</span>
        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>
            <span class="n">metric</span> <span class="o">=</span> <span class="s2">&quot;mse&quot;</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">auto_metric_sklearn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="s2">&quot;regression&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
            <span class="n">metric</span> <span class="o">=</span> <span class="s2">&quot;log_loss&quot;</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">auto_metric_sklearn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="s2">&quot;binary&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span>
            <span class="n">metric</span> <span class="o">=</span> <span class="s2">&quot;log_loss&quot;</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">auto_metric_sklearn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
        <span class="k">return</span> <span class="n">metric</span><span class="p">,</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="AbstractModel._bayes_eval">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._bayes_eval.html#tabensemb.model.AbstractModel._bayes_eval">[docs]</a>
    <span class="k">def</span> <span class="nf">_bayes_eval</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">X_train</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">,</span>
        <span class="n">X_val</span><span class="p">,</span>
        <span class="n">y_val</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the model for Bayesian optimization iterations. The larger one of the training loss and the validation</span>
<span class="sd">        loss is returned by default.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model</span>
<span class="sd">            The model returned by :meth:`_new_model`.</span>
<span class="sd">        X_train</span>
<span class="sd">            The training data from :meth:`_train_data_preprocess`.</span>
<span class="sd">        y_train</span>
<span class="sd">            The target of the training data from :meth:`_train_data_preprocess`.</span>
<span class="sd">        X_val</span>
<span class="sd">            The validation data from :meth:`_train_data_preprocess`.</span>
<span class="sd">        y_val</span>
<span class="sd">            The target of the validation data from :meth:`_train_data_preprocess`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The metric of the Bayesian hyperparameter optimization iteration.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y_val_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pred_single_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_metric_sklearn</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">y_val_pred</span><span class="p">)</span>
        <span class="n">y_train_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pred_single_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">train_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_metric_sklearn</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">([</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">])</span></div>


<div class="viewcode-block" id="AbstractModel._check_train_status">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._check_train_status.html#tabensemb.model.AbstractModel._check_train_status">[docs]</a>
    <span class="k">def</span> <span class="nf">_check_train_status</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Raise exception if _predict is called and the model base is not trained.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trained</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="si">}</span><span class="s2"> not trained, run </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.train() first.&quot;</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="AbstractModel._get_params">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._get_params.html#tabensemb.model.AbstractModel._get_params">[docs]</a>
    <span class="k">def</span> <span class="nf">_get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load default parameters or optimized parameters (if Bayesian optimization is performed) of the selected model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name:</span>
<span class="sd">            The name of a selected model.</span>
<span class="sd">        verbose:</span>
<span class="sd">            Verbosity</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            A dict of parameters that contains all keys in :meth:`_initial_values`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">model_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Previous params loaded: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_params</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_params</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span></div>


<div class="viewcode-block" id="AbstractModel._update_optimizer_lr_scheduler_params">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._update_optimizer_lr_scheduler_params.html#tabensemb.model.AbstractModel._update_optimizer_lr_scheduler_params">[docs]</a>
    <span class="k">def</span> <span class="nf">_update_optimizer_lr_scheduler_params</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update parameters of the optimizer and the lr_scheduler according to the input hyperparameters when</span>
<span class="sd">        initializing a model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name</span>
<span class="sd">            The name of the model</span>
<span class="sd">        kwargs</span>
<span class="sd">            Parameters to train the model returned by :meth:`_get_params`. It contains all arguments in</span>
<span class="sd">            :meth:`_initial_values`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        str</span>
<span class="sd">            The name of the optimizer in torch.optim</span>
<span class="sd">        Dict</span>
<span class="sd">            The parameters of the optimizer</span>
<span class="sd">        str</span>
<span class="sd">            The name of the lr scheduler in torch.optim.lr_scheduler</span>
<span class="sd">        Dict</span>
<span class="sd">            The parameters of the lr scheduler</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">opt_name</span><span class="p">,</span> <span class="n">opt_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
        <span class="n">opt_params</span> <span class="o">=</span> <span class="n">opt_params</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">opt_params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">opt_params</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
        <span class="p">)</span>
        <span class="n">lrs_name</span><span class="p">,</span> <span class="n">lrs_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedulers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
        <span class="n">lrs_params</span> <span class="o">=</span> <span class="n">lrs_params</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">lrs_params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">lrs_params</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">opt_name</span><span class="p">,</span> <span class="n">opt_params</span><span class="p">,</span> <span class="n">lrs_name</span><span class="p">,</span> <span class="n">lrs_params</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_trained</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        True if :meth:`train` has been called, otherwise False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_support_warm_start</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        If the model base cannot finetune a model, this is set to False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">True</span>

<div class="viewcode-block" id="AbstractModel._check_space">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._check_space.html#tabensemb.model.AbstractModel._check_space">[docs]</a>
    <span class="k">def</span> <span class="nf">_check_space</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if all parameters defined in :meth:`_initial_values` have corresponding search spaces defined in</span>
<span class="sd">        :meth:`_space`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">any_mismatch</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model_names</span><span class="p">():</span>
            <span class="n">tmp_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_params</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">space</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_space</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">space</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">not_exist</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">space</span> <span class="k">if</span> <span class="n">s</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tmp_params</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">not_exist</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">not_exist</span><span class="si">}</span><span class="s2"> are defined for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> in _space but are not defined in &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;_initial_values.&quot;</span>
                <span class="p">)</span>
                <span class="n">any_mismatch</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">any_mismatch</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Defined spaces and initial values do not match.&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbstractModel._mkdir">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._mkdir.html#tabensemb.model.AbstractModel._mkdir">[docs]</a>
    <span class="k">def</span> <span class="nf">_mkdir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a directory for the model base under the root of the linked :class:`~tabensemb.trainer.Trainer`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">project_root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbstractModel.get_model_names">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel.get_model_names.html#tabensemb.model.AbstractModel.get_model_names">[docs]</a>
    <span class="k">def</span> <span class="nf">get_model_names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get names of available models based on :meth:`_get_model_names` and the arguments ``model_subset`` or</span>
<span class="sd">        ``exclude_models`` of :meth:`__init__`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list</span>
<span class="sd">            Names of available models.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_subset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_subset</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">model</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_model_names</span><span class="p">():</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2"> not available for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_subset</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">exclude_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_model_names</span><span class="p">()</span>
            <span class="n">used_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">names</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">exclude_models</span><span class="p">]</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">used_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_model_names</span><span class="p">()</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">res</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_conditional_validity</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="AbstractModel._get_model_names">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._get_model_names.html#tabensemb.model.AbstractModel._get_model_names">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_get_model_names</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get names of all available models implemented in the model base.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list</span>
<span class="sd">            Names of available models.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


<div class="viewcode-block" id="AbstractModel._get_program_name">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._get_program_name.html#tabensemb.model.AbstractModel._get_program_name">[docs]</a>
    <span class="k">def</span> <span class="nf">_get_program_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the default name of the model base.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        str</span>
<span class="sd">            The default name of the model base.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


    <span class="c1"># The following methods are for the default _train and _predict methods. If users directly overload _train and</span>
    <span class="c1"># _predict, the following methods are not required to be implemented.</span>
<div class="viewcode-block" id="AbstractModel._new_model">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._new_model.html#tabensemb.model.AbstractModel._new_model">[docs]</a>
    <span class="k">def</span> <span class="nf">_new_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate a new selected model based on kwargs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name:</span>
<span class="sd">            The name of a selected model.</span>
<span class="sd">        verbose:</span>
<span class="sd">            Verbosity.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Parameters to generate the model returned by :meth:`_get_params`. It contains all arguments in</span>
<span class="sd">            :meth:`_initial_values`. If any model is required, which is defined in :meth:`required_models`, there will</span>
<span class="sd">            be a named argument &quot;required_models&quot; containing required models extracted by :meth:`_get_required_models`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        model:</span>
<span class="sd">            A new model (without any restriction to its type). It will be passed to :meth:`_train_single_model` and</span>
<span class="sd">            :meth:`_pred_single_model`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :meth:`new_model`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


<div class="viewcode-block" id="AbstractModel._train_data_preprocess">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._train_data_preprocess.html#tabensemb.model.AbstractModel._train_data_preprocess">[docs]</a>
    <span class="k">def</span> <span class="nf">_train_data_preprocess</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">DataModule</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Processing the data from ``self.trainer.datamodule`` for training.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name:</span>
<span class="sd">            The name of a selected model.</span>
<span class="sd">        warm_start</span>
<span class="sd">            Finetune models based on previous trained models.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            A dictionary that has the following keys: X_train, y_train, X_val, y_val, X_test, y_test.</span>
<span class="sd">            Those with postfixes ``_train`` or ``_val`` will be passed to :meth:`_train_single_model` and</span>
<span class="sd">            :meth:`_bayes_eval`. All of them will be passed to :meth:`_pred_single_model` for evaluation.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        ``self.trainer.datamodule.X_train/val/test`` are not scaled. To scale the df,</span>
<span class="sd">        run ``df = datamodule.data_transform(df, scaler_only=True)``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


<div class="viewcode-block" id="AbstractModel._data_preprocess">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._data_preprocess.html#tabensemb.model.AbstractModel._data_preprocess">[docs]</a>
    <span class="k">def</span> <span class="nf">_data_preprocess</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform the same preprocessing as in :meth:`_train_data_preprocess` on a new dataset.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        df:</span>
<span class="sd">            The new tabular dataset that has the same structure as ``self.trainer.datamodule.X_test``</span>
<span class="sd">        derived_data:</span>
<span class="sd">            Unstacked data derived from :meth:`tabensemb.data.datamodule.DataModule.derive_unstacked`. If None,</span>
<span class="sd">            unstacked data will be re-derived.</span>
<span class="sd">        model_name:</span>
<span class="sd">            The name of a selected model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Any</span>
<span class="sd">            The processed data that has the same structure as X_test from :meth:`_train_data_preprocess`.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The input df is not scaled. To scale the df, run ``df = datamodule.data_transform(df, scaler_only=True)``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


<div class="viewcode-block" id="AbstractModel._train_single_model">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._train_single_model.html#tabensemb.model.AbstractModel._train_single_model">[docs]</a>
    <span class="k">def</span> <span class="nf">_train_single_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">X_train</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">X_val</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">y_val</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">warm_start</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">in_bayes_opt</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Training the model (initialized in :meth:`_new_model`).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model:</span>
<span class="sd">            The model returned by :meth:`_new_model`.</span>
<span class="sd">        model_name:</span>
<span class="sd">            The name of the model.</span>
<span class="sd">        epoch:</span>
<span class="sd">            Total epochs to train the model.</span>
<span class="sd">        X_train:</span>
<span class="sd">            The training data from :func:`_train_data_preprocess`.</span>
<span class="sd">        y_train:</span>
<span class="sd">            The training target from :func:`_train_data_preprocess`.</span>
<span class="sd">        X_val:</span>
<span class="sd">            The validation data from :func:`_train_data_preprocess`.</span>
<span class="sd">        y_val:</span>
<span class="sd">            The validation target from :func:`_train_data_preprocess`.</span>
<span class="sd">        verbose:</span>
<span class="sd">            Verbosity.</span>
<span class="sd">        warm_start:</span>
<span class="sd">            Finetune models based on previous trained models.</span>
<span class="sd">        in_bayes_opt:</span>
<span class="sd">            Whether is in a Bayesian optimization loop.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Parameters to train the model returned by :meth:`_get_params`. It contains all arguments in</span>
<span class="sd">            :meth:`_initial_values`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


<div class="viewcode-block" id="AbstractModel._pred_single_model">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._pred_single_model.html#tabensemb.model.AbstractModel._pred_single_model">[docs]</a>
    <span class="k">def</span> <span class="nf">_pred_single_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">X_test</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict using the model trained in :meth:`_train_single_model`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model:</span>
<span class="sd">            The model returned by :meth:`_new_model` and trained in :meth:`_train_single_model`.</span>
<span class="sd">        X_test:</span>
<span class="sd">            The data from :meth:`_data_preprocess` or :meth:`_train_data_preprocess`.</span>
<span class="sd">        verbose:</span>
<span class="sd">            Verbosity.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Parameters to train the model returned by :meth:`_get_params`. It contains all arguments in</span>
<span class="sd">            :meth:`_initial_values`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">            Prediction of the target.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        For deep learning models with mini-batch training (dataloaders), if an :class:`AbstractWrapper` will be used to extract</span>
<span class="sd">        hidden representations, the ``batch_size`` when inferring should be the length of the dataset. See</span>
<span class="sd">        :meth:`tabensemb.model.PytorchTabular._pred_single_model` and :meth:`tabensemb.model.WideDeep._pred_single_model`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


<div class="viewcode-block" id="AbstractModel._space">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._space.html#tabensemb.model.AbstractModel._space">[docs]</a>
    <span class="k">def</span> <span class="nf">_space</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Integer</span><span class="p">,</span> <span class="n">Real</span><span class="p">,</span> <span class="n">Categorical</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A list of ``scikit-optimize`` search spaces for the selected model. It should contain all parameters</span>
<span class="sd">        defined in :meth:`_initial_values`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name:</span>
<span class="sd">            The name of a selected model that is currently going through Bayesian optimization.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list</span>
<span class="sd">            A list of ``skopt.space``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


<div class="viewcode-block" id="AbstractModel._initial_values">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._initial_values.html#tabensemb.model.AbstractModel._initial_values">[docs]</a>
    <span class="k">def</span> <span class="nf">_initial_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initial values of hyperparameters to be optimized.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name:</span>
<span class="sd">            The name of a selected model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            A dict of initial hyperparameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


<div class="viewcode-block" id="AbstractModel._conditional_validity">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractModel._conditional_validity.html#tabensemb.model.AbstractModel._conditional_validity">[docs]</a>
    <span class="k">def</span> <span class="nf">_conditional_validity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check the validity of a model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name:</span>
<span class="sd">            The name of a model in :meth:`_get_model_names`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool</span>
<span class="sd">            Whether the model can be trained under certain settings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">True</span></div>
</div>



<span class="k">class</span> <span class="nc">BayesCallback</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Print information when performing Bayesian optimization.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">total</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total</span> <span class="o">=</span> <span class="n">total</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cnt</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postfix</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;ls&quot;</span><span class="p">:</span> <span class="mf">1e8</span><span class="p">,</span>
            <span class="s2">&quot;param&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;min ls&quot;</span><span class="p">:</span> <span class="mf">1e8</span><span class="p">,</span>
            <span class="s2">&quot;min param&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;min at&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">result</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postfix</span><span class="p">[</span><span class="s2">&quot;ls&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">func_vals</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postfix</span><span class="p">[</span><span class="s2">&quot;param&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;__round__&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">x_iters</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">postfix</span><span class="p">[</span><span class="s2">&quot;min ls&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">postfix</span><span class="p">[</span><span class="s2">&quot;min ls&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">postfix</span><span class="p">[</span><span class="s2">&quot;min param&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                <span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;__round__&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>
            <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">postfix</span><span class="p">[</span><span class="s2">&quot;min at&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">func_vals</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">tot_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_time</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Bayes-opt </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">cnt</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">total</span><span class="si">}</span><span class="s2">, tot </span><span class="si">{</span><span class="n">tot_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s, avg </span><span class="si">{</span><span class="n">tot_time</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">cnt</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s/it: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">postfix</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>


<div class="viewcode-block" id="TorchModel">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel.html#tabensemb.model.TorchModel">[docs]</a>
<span class="k">class</span> <span class="nc">TorchModel</span><span class="p">(</span><span class="n">AbstractModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The class for PyTorch-like models. Some abstract methods in :class:`AbstractModel` are implemented.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="TorchModel.__init__">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel.html#tabensemb.model.TorchModel.__init__">[docs]</a>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">lightning_trainer_kwargs</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TorchModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lightning_trainer_kwargs</span> <span class="o">=</span> <span class="n">lightning_trainer_kwargs</span></div>


<div class="viewcode-block" id="TorchModel.cal_feature_importance">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel.cal_feature_importance.html#tabensemb.model.TorchModel.cal_feature_importance">[docs]</a>
    <span class="k">def</span> <span class="nf">cal_feature_importance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">,</span>
        <span class="n">method</span><span class="p">,</span>
        <span class="n">call_general_method</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">:</span> <span class="n">Iterable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate feature importance using a specified model. ``captum`` or ``shap`` is called.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name</span>
<span class="sd">            The selected model in the model base.</span>
<span class="sd">        method</span>
<span class="sd">            The method to calculate importance. &quot;permutation&quot; or &quot;shap&quot;.</span>
<span class="sd">        call_general_method</span>
<span class="sd">            Call the general feature importance calculation :meth:`AbstractModel.cal_feature_importance` instead of the</span>
<span class="sd">            optimized procedure for deep learning models. This is useful when calculating the feature importance of</span>
<span class="sd">            models that require other models.</span>
<span class="sd">        indices</span>
<span class="sd">            The indices of data points where feature importance values are evaluated</span>
<span class="sd">        kwargs</span>
<span class="sd">            Arguments for :meth:`tabensemb.model.AbstractModel.cal_feature_importance` or</span>
<span class="sd">            :meth:`tabensemb.model.AbstractModel.cal_shap`</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        attr</span>
<span class="sd">            Values of feature importance.</span>
<span class="sd">        importance_names</span>
<span class="sd">            Corresponding feature names. All features including derived unstacked features will be included.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">call_general_method</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">TorchModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">cal_feature_importance</span><span class="p">(</span>
                <span class="n">model_name</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>

        <span class="n">label_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">label_data</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">test_indices</span> <span class="k">if</span> <span class="n">indices</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">indices</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">label_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">indices</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">trainer_datamodule</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span>

        <span class="c1"># This is decomposed from _data_preprocess (The first part)</span>
        <span class="n">tensors</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">custom_datamodule</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_tensors</span><span class="p">(</span>
            <span class="n">trainer_datamodule</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">indices</span><span class="p">,</span> <span class="p">:],</span>
            <span class="n">trainer_datamodule</span><span class="o">.</span><span class="n">get_derived_data_slice</span><span class="p">(</span>
                <span class="n">trainer_datamodule</span><span class="o">.</span><span class="n">derived_data</span><span class="p">,</span> <span class="n">indices</span>
            <span class="p">),</span>
            <span class="n">model_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">D</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">cont_feature_names</span> <span class="o">=</span> <span class="n">custom_datamodule</span><span class="o">.</span><span class="n">cont_feature_names</span>
        <span class="n">cat_feature_names</span> <span class="o">=</span> <span class="n">custom_datamodule</span><span class="o">.</span><span class="n">cat_feature_names</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;permutation&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">required_models</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Calculating permutation importance for models that require other models. Results of required &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;models come from un-permuted data. If this is not acceptable, pass `call_general_method=True`.&quot;</span>
                <span class="p">)</span>

            <span class="k">def</span> <span class="nf">forward_func</span><span class="p">(</span><span class="n">_X</span><span class="p">,</span> <span class="o">*</span><span class="n">_D</span><span class="p">):</span>
                <span class="c1"># This is decomposed from _data_preprocess (The second part)</span>
                <span class="n">_tensors</span> <span class="o">=</span> <span class="p">(</span><span class="n">_X</span><span class="p">,</span> <span class="o">*</span><span class="n">_D</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_dataset_from_tensors</span><span class="p">(</span>
                    <span class="n">_tensors</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">model_name</span>
                <span class="p">)</span>
                <span class="c1"># This is decomposed from _predict</span>
                <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pred_single_model</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">model_name</span><span class="p">],</span>
                    <span class="n">X_test</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">metric_sklearn</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">prediction</span><span class="p">,</span> <span class="s2">&quot;mse&quot;</span><span class="p">))</span>
                <span class="k">return</span> <span class="n">loss</span>

            <span class="n">feature_perm</span> <span class="o">=</span> <span class="n">FeaturePermutation</span><span class="p">(</span><span class="n">forward_func</span><span class="p">)</span>
            <span class="n">attr</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">feature_perm</span><span class="o">.</span><span class="n">attribute</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">D</span><span class="p">))]</span>
            <span class="n">attr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">attr</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;shap&quot;</span><span class="p">:</span>
            <span class="n">attr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cal_shap</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">derived_data</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
        <span class="n">importance_names</span> <span class="o">=</span> <span class="n">cp</span><span class="p">(</span><span class="n">cont_feature_names</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key_idx</span><span class="p">,</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">derived_data</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="n">importance_names</span> <span class="o">+=</span> <span class="p">(</span>
                <span class="n">custom_datamodule</span><span class="o">.</span><span class="n">unstacked_col_names</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">custom_datamodule</span><span class="o">.</span><span class="n">unstacked_col_names</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                <span class="k">else</span> <span class="n">trainer_datamodule</span><span class="o">.</span><span class="n">unstacked_col_names</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">attr</span><span class="p">,</span> <span class="n">importance_names</span></div>


<div class="viewcode-block" id="TorchModel.cal_shap">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel.cal_shap.html#tabensemb.model.TorchModel.cal_shap">[docs]</a>
    <span class="k">def</span> <span class="nf">cal_shap</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">call_general_method</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">return_importance</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">n_background</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">init_kwargs</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">shap_values_kwargs</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">:</span> <span class="n">Iterable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate SHAP values using a specified model. The ``shap.DeepExplainer`` is used.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name</span>
<span class="sd">            The selected model in the model base.</span>
<span class="sd">        call_general_method</span>
<span class="sd">            Call the general shap calculation :meth:`AbstractModel.cal_shap` instead of the</span>
<span class="sd">            optimized procedure for deep learning models. This is useful when calculating the feature importance of</span>
<span class="sd">            models that require other models.</span>
<span class="sd">        return_importance</span>
<span class="sd">            True to return mean absolute SHAP values. False to return ``shap.DeepExplainer``, ``shap.Explanation``, and</span>
<span class="sd">            results of :meth:``shap.DeepExplainer.shap_values``</span>
<span class="sd">        n_background</span>
<span class="sd">            Number of randomly sampled background (training) data passed to ``shap.DeepExplainer``.</span>
<span class="sd">        init_kwargs</span>
<span class="sd">            Arguments of ``shap.DeepExplainer.__init__``</span>
<span class="sd">        shap_values_kwargs</span>
<span class="sd">            Arguments of ``shap.DeepExplainer.shap_values``</span>
<span class="sd">        indices</span>
<span class="sd">            The indices of data points where shap values are evaluated</span>
<span class="sd">        kwargs</span>
<span class="sd">            Ignored.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        attr</span>
<span class="sd">            The SHAP values. All features including derived unstacked features will be included.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">required_models</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Calculating shap for models that require other models is not supported, because &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;shap.DeepExplainer directly calls forward passing a series of tensors, and required models may &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;use DataFrames, NDArrays, etc. Pass `call_general_method=True` to use shap.KernelExplainer.&quot;</span>
            <span class="p">)</span>
        <span class="kn">import</span> <span class="nn">shap</span>

        <span class="n">train_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train_indices</span>
        <span class="n">test_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">test_indices</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">test_indices</span> <span class="k">if</span> <span class="n">indices</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">indices</span>
        <span class="n">datamodule</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span>
        <span class="k">if</span> <span class="s2">&quot;categorical&quot;</span> <span class="ow">in</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">derived_data</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;shap.DeepExplainer cannot handle categorical features because their gradients (as float dtype) are &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;zero, and integers can not require_grad. If shap values of categorical values are needed, pass &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;`call_general_method=True` to use shap.KernelExplainer.&quot;</span>
            <span class="p">)</span>

        <span class="n">bk_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
            <span class="n">train_indices</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="nb">min</span><span class="p">([</span><span class="n">n_background</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_indices</span><span class="p">)]),</span>
            <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">tensors</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_tensors</span><span class="p">(</span>
            <span class="n">datamodule</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">bk_indices</span><span class="p">,</span> <span class="p">:],</span>
            <span class="n">datamodule</span><span class="o">.</span><span class="n">get_derived_data_slice</span><span class="p">(</span><span class="n">datamodule</span><span class="o">.</span><span class="n">derived_data</span><span class="p">,</span> <span class="n">bk_indices</span><span class="p">),</span>
            <span class="n">model_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">X_train_bk</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">D_train_bk</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">background_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_train_bk</span><span class="p">,</span> <span class="o">*</span><span class="n">D_train_bk</span><span class="p">]</span>

        <span class="n">tensors</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_tensors</span><span class="p">(</span>
            <span class="n">datamodule</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">indices</span><span class="p">,</span> <span class="p">:],</span>
            <span class="n">datamodule</span><span class="o">.</span><span class="n">get_derived_data_slice</span><span class="p">(</span><span class="n">datamodule</span><span class="o">.</span><span class="n">derived_data</span><span class="p">,</span> <span class="n">indices</span><span class="p">),</span>
            <span class="n">model_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">D_test</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">test_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_test</span><span class="p">,</span> <span class="o">*</span><span class="n">D_test</span><span class="p">]</span>

        <span class="k">with</span> <span class="n">global_setting</span><span class="p">({</span><span class="s2">&quot;test_with_no_grad&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}):</span>
            <span class="n">init_kwargs_</span> <span class="o">=</span> <span class="n">update_defaults_by_kwargs</span><span class="p">(</span><span class="nb">dict</span><span class="p">(),</span> <span class="n">init_kwargs</span><span class="p">)</span>
            <span class="n">explainer_</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">DeepExplainer</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">model_name</span><span class="p">],</span> <span class="n">background_data</span><span class="p">,</span> <span class="o">**</span><span class="n">init_kwargs_</span>
            <span class="p">)</span>
            <span class="c1"># TODO: in PytorchDeep, ``model_output_values.cpu()`` at</span>
            <span class="c1">#  ``_check_additivity(self, model_output_values.cpu(), output_phis)``  is not valid because the output</span>
            <span class="c1">#  has gradient.</span>
            <span class="n">shap_values_kwargs_</span> <span class="o">=</span> <span class="n">update_defaults_by_kwargs</span><span class="p">(</span>
                <span class="nb">dict</span><span class="p">(</span><span class="n">check_additivity</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">shap_values_kwargs</span>
            <span class="p">)</span>
            <span class="k">with</span> <span class="n">HiddenPrints</span><span class="p">():</span>
                <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer_</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_values_kwargs_</span><span class="p">)</span>

        <span class="n">attr</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)]</span>
                <span class="o">+</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">shap_values</span><span class="p">[</span><span class="mi">1</span><span class="p">:]],</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
            <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">attr</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">if</span> <span class="n">return_importance</span> <span class="k">else</span> <span class="p">(</span><span class="n">explainer_</span><span class="p">,</span> <span class="n">shap_values</span><span class="p">)</span></div>


<div class="viewcode-block" id="TorchModel._train_data_preprocess">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel._train_data_preprocess.html#tabensemb.model.TorchModel._train_data_preprocess">[docs]</a>
    <span class="k">def</span> <span class="nf">_train_data_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">datamodule</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_custom_datamodule</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span><span class="p">)</span>
        <span class="n">datamodule</span><span class="o">.</span><span class="n">update_dataset</span><span class="p">()</span>
        <span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_dataset</span><span class="p">(</span>
            <span class="n">datamodule</span><span class="p">,</span> <span class="n">model_name</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;X_train&quot;</span><span class="p">:</span> <span class="n">train_dataset</span><span class="p">,</span>
            <span class="s2">&quot;y_train&quot;</span><span class="p">:</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span>
            <span class="s2">&quot;X_val&quot;</span><span class="p">:</span> <span class="n">val_dataset</span><span class="p">,</span>
            <span class="s2">&quot;y_val&quot;</span><span class="p">:</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">y_val</span><span class="p">,</span>
            <span class="s2">&quot;X_test&quot;</span><span class="p">:</span> <span class="n">test_dataset</span><span class="p">,</span>
            <span class="s2">&quot;y_test&quot;</span><span class="p">:</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">y_test</span><span class="p">,</span>
        <span class="p">}</span></div>


<div class="viewcode-block" id="TorchModel._prepare_custom_datamodule">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel._prepare_custom_datamodule.html#tabensemb.model.TorchModel._prepare_custom_datamodule">[docs]</a>
    <span class="k">def</span> <span class="nf">_prepare_custom_datamodule</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataModule</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Change this method if a customized preprocessing stage is needed. See :class:`tabensemb.model.CatEmbed` for example.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :meth:`_run_custom_data_module`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span></div>


<div class="viewcode-block" id="TorchModel._generate_dataset">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel._generate_dataset.html#tabensemb.model.TorchModel._generate_dataset">[docs]</a>
    <span class="k">def</span> <span class="nf">_generate_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datamodule</span><span class="p">:</span> <span class="n">DataModule</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate ``torch.utils.data.Dataset`` for training.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        datamodule</span>
<span class="sd">            The :class:`tabensemb.data.datamodule.DataModule` returned by :meth:`_prepare_custom_datamodule`.</span>
<span class="sd">        model_name</span>
<span class="sd">            The name of the selected model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.utils.data.Dataset</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :meth:`_generate_dataset_from_tensors`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">required_models</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_required_models</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">required_models</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">required_models</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">datamodule</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">datamodule</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">,</span>
                <span class="n">datamodule</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_dataset_for_required_models</span><span class="p">(</span>
                <span class="n">df</span><span class="o">=</span><span class="n">datamodule</span><span class="o">.</span><span class="n">df</span><span class="p">,</span>
                <span class="n">derived_data</span><span class="o">=</span><span class="n">datamodule</span><span class="o">.</span><span class="n">derived_data</span><span class="p">,</span>
                <span class="n">tensors</span><span class="o">=</span><span class="n">datamodule</span><span class="o">.</span><span class="n">tensors</span><span class="p">,</span>
                <span class="n">required_models</span><span class="o">=</span><span class="n">required_models</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">generate_subset</span><span class="p">(</span>
                <span class="n">dataset</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">test_dataset</span></div>


<div class="viewcode-block" id="TorchModel.get_full_name_from_required_model">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel.get_full_name_from_required_model.html#tabensemb.model.TorchModel.get_full_name_from_required_model">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_full_name_from_required_model</span><span class="p">(</span><span class="n">required_model</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the name of a required model to store or access data in ``derived_tensors`` passed to</span>
<span class="sd">        :meth:`AbstractNN._forward`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        required_model</span>
<span class="sd">            A required model specified in :meth:`AbstractModel.required_models` and extracted by</span>
<span class="sd">            :meth:`AbstractModel._get_required_models`.</span>
<span class="sd">        model_name</span>
<span class="sd">            The name of the required model. It is necessary if the model comes from the same model base.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        str</span>
<span class="sd">            The name of a required model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">required_model</span><span class="p">,</span> <span class="n">AbstractWrapper</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">required_model</span><span class="p">,</span> <span class="n">AbstractModel</span>
        <span class="p">):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">required_model</span><span class="o">.</span><span class="n">get_model_names</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">full_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;EXTERN_</span><span class="si">{</span><span class="n">required_model</span><span class="o">.</span><span class="n">program</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">required_model</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">model_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;If the required model comes from the same model base, `model_name` should be &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;provided when calling `call_required_model.`&quot;</span>
                <span class="p">)</span>
            <span class="n">full_name</span> <span class="o">=</span> <span class="n">model_name</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The required model should be a nn.Module, an AbstractWrapper, or an AbstractModel, but got&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">required_model</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead. If you are using jupyter notebook and its autoreload plugin,&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;the reloaded class is different from the original one, although their names are the same.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">full_name</span></div>


<div class="viewcode-block" id="TorchModel._generate_dataset_for_required_models">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel._generate_dataset_for_required_models.html#tabensemb.model.TorchModel._generate_dataset_for_required_models">[docs]</a>
    <span class="k">def</span> <span class="nf">_generate_dataset_for_required_models</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">required_models</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call :meth:`AbstractModel._data_preprocess` to generate the dataset, output, and hidden representations for the</span>
<span class="sd">        required model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        df</span>
<span class="sd">            The new tabular dataset that has the same structure as ``self.trainer.datamodule.X_test``</span>
<span class="sd">        derived_data</span>
<span class="sd">            Unstacked data derived from :meth:`tabensemb.data.datamodule.DataModule.derive_unstacked`.</span>
<span class="sd">        tensors</span>
<span class="sd">            Tensors stored in a :class:`tabensemb.data.datamodule.DataModule` and obtained by</span>
<span class="sd">            :meth:`tabensemb.data.datamodule.DataModule.update_dataset`</span>
<span class="sd">        required_models</span>
<span class="sd">            Required models specified in :meth:`AbstractModel.required_models` and extracted by</span>
<span class="sd">            :meth:`AbstractModel._get_required_models`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.utils.data.Dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">full_data_required_models</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">required_models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">full_name</span> <span class="o">=</span> <span class="n">TorchModel</span><span class="o">.</span><span class="n">get_full_name_from_required_model</span><span class="p">(</span>
                <span class="n">mod</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="n">name</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">AbstractNN</span><span class="p">):</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">_data_preprocess</span><span class="p">(</span>
                    <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
                    <span class="n">derived_data</span><span class="o">=</span><span class="n">derived_data</span><span class="p">,</span>
                    <span class="n">model_name</span><span class="o">=</span><span class="n">full_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                <span class="p">)</span>
                <span class="n">full_data_required_models</span><span class="p">[</span><span class="n">full_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">AbstractNN</span><span class="o">.</span><span class="n">call_required_model</span><span class="p">(</span>
                    <span class="n">mod</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;data_required_models&quot;</span><span class="p">:</span> <span class="p">{</span><span class="n">full_name</span><span class="p">:</span> <span class="n">data</span><span class="p">}}</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="n">full_data_required_models</span><span class="p">[</span><span class="n">full_name</span> <span class="o">+</span> <span class="s2">&quot;_pred&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">AbstractWrapper</span><span class="p">):</span>
                    <span class="n">hidden</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">hidden_representation</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                    <span class="n">full_data_required_models</span><span class="p">[</span><span class="n">full_name</span> <span class="o">+</span> <span class="s2">&quot;_hidden&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hidden</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">mod</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">res</span> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><span class="o">*</span><span class="n">tensors</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="n">hidden</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">hidden_representation</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="n">full_data_required_models</span><span class="p">[</span><span class="n">full_name</span> <span class="o">+</span> <span class="s2">&quot;_pred&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span>
                <span class="n">full_data_required_models</span><span class="p">[</span><span class="n">full_name</span> <span class="o">+</span> <span class="s2">&quot;_hidden&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hidden</span>
        <span class="n">tensor_dataset</span> <span class="o">=</span> <span class="n">Data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span><span class="o">*</span><span class="n">tensors</span><span class="p">)</span>
        <span class="n">dict_df_dataset</span> <span class="o">=</span> <span class="n">DictMixDataset</span><span class="p">(</span><span class="n">full_data_required_models</span><span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">DictDataset</span><span class="p">(</span>
            <span class="n">ListDataset</span><span class="p">([</span><span class="n">tensor_dataset</span><span class="p">,</span> <span class="n">dict_df_dataset</span><span class="p">]),</span>
            <span class="n">keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;self&quot;</span><span class="p">,</span> <span class="s2">&quot;required&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">dataset</span></div>


<div class="viewcode-block" id="TorchModel._run_custom_data_module">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel._run_custom_data_module.html#tabensemb.model.TorchModel._run_custom_data_module">[docs]</a>
    <span class="k">def</span> <span class="nf">_run_custom_data_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Change this method if a customized preprocessing stage is implemented in :meth:`_prepare_custom_datamodule`.</span>
<span class="sd">        See :class:`tabensemb.model.CatEmbed` for example.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :meth:`_prepare_custom_datamodule`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span></div>


<div class="viewcode-block" id="TorchModel._prepare_tensors">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel._prepare_tensors.html#tabensemb.model.TorchModel._prepare_tensors">[docs]</a>
    <span class="k">def</span> <span class="nf">_prepare_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transform the upcoming dataset into Tensors that has the same structures as those stored in a</span>
<span class="sd">        :class:`tabensemb.data.datamodule.DataModule` and obtained by</span>
<span class="sd">        :meth:`tabensemb.data.datamodule.DataModule.update_dataset`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        df</span>
<span class="sd">            The new tabular dataset that has the same structure as ``self.trainer.datamodule.X_test``</span>
<span class="sd">        derived_data</span>
<span class="sd">            Unstacked data derived from :meth:`tabensemb.data.datamodule.DataModule.derive_unstacked`.</span>
<span class="sd">        model_name</span>
<span class="sd">            The name of the selected model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A tuple of torch.Tensor</span>
<span class="sd">            Transformed tensors.</span>
<span class="sd">        pd.DataFrame</span>
<span class="sd">            The transformed dataset after running :meth:`_run_custom_data_module`.</span>
<span class="sd">        dict</span>
<span class="sd">            The derived unstacked data after running :meth:`_run_custom_data_module`</span>
<span class="sd">        DataModule</span>
<span class="sd">            The :class:`tabensemb.data.datamodule.DataModule` returned by :meth:`_prepare_custom_data_module`</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :meth:`tabensemb.data.datamodule.DataModule.update_dataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">datamodule</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_custom_data_module</span><span class="p">(</span>
            <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">model_name</span>
        <span class="p">)</span>
        <span class="n">scaled_df</span> <span class="o">=</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">data_transform</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">scaler_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">generate_tensors</span><span class="p">(</span><span class="n">scaled_df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">)</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">D</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">datamodule</span></div>


<div class="viewcode-block" id="TorchModel._generate_dataset_from_tensors">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel._generate_dataset_from_tensors.html#tabensemb.model.TorchModel._generate_dataset_from_tensors">[docs]</a>
    <span class="k">def</span> <span class="nf">_generate_dataset_from_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform the same preprocessing as in :meth:`_generate_dataset` on a new dataset.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensors</span>
<span class="sd">            Tensors that has the same structures as those stored in a :class:`tabensemb.data.datamodule.DataModule` and</span>
<span class="sd">            obtained by :meth:`tabensemb.data.datamodule.DataModule.update_dataset`.</span>
<span class="sd">        df</span>
<span class="sd">            The transformed dataset after running :meth:`_run_custom_data_module`.</span>
<span class="sd">        derived_data</span>
<span class="sd">            The derived unstacked data after running :meth:`_run_custom_data_module`</span>
<span class="sd">        model_name</span>
<span class="sd">            The name of the selected model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.utils.data.Dataset</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :meth:`_generate_dataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">required_models</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_required_models</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">required_models</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">Data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span><span class="o">*</span><span class="n">tensors</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_dataset_for_required_models</span><span class="p">(</span>
                <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>  <span class="c1"># Use the unscaled one here</span>
                <span class="n">derived_data</span><span class="o">=</span><span class="n">derived_data</span><span class="p">,</span>
                <span class="n">tensors</span><span class="o">=</span><span class="n">tensors</span><span class="p">,</span>
                <span class="n">required_models</span><span class="o">=</span><span class="n">required_models</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">dataset</span></div>


<div class="viewcode-block" id="TorchModel._data_preprocess">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel._data_preprocess.html#tabensemb.model.TorchModel._data_preprocess">[docs]</a>
    <span class="k">def</span> <span class="nf">_data_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
        <span class="c1"># In _train_data_preprocess:</span>
        <span class="c1"># 1. prepare_custom_datamodule + DataModule.update_dataset</span>
        <span class="c1"># 2. _generate_dataset using tensors in DataModule</span>
        <span class="c1"># In _data_preprocess</span>
        <span class="c1"># 0. Check the label(s).</span>
        <span class="c1"># 1. _prepare_tensors = _run_custom_data_module + update_dataset</span>
        <span class="c1"># 2. _generate_dataset_from_tensors is very similar to _generate_dataset, but does not split it into three parts.</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">label_name</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">label</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="c1"># Just to create a placeholder for datamodule.generate_tensors.</span>
                <span class="n">df</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="n">label</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">tensors</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_tensors</span><span class="p">(</span>
            <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">model_name</span>
        <span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_dataset_from_tensors</span><span class="p">(</span>
            <span class="n">tensors</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">derived_data</span><span class="p">,</span> <span class="n">model_name</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">dataset</span></div>


<div class="viewcode-block" id="TorchModel._train_single_model">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel._train_single_model.html#tabensemb.model.TorchModel._train_single_model">[docs]</a>
    <span class="k">def</span> <span class="nf">_train_single_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;AbstractNN&quot;</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">,</span>
        <span class="n">epoch</span><span class="p">,</span>
        <span class="n">X_train</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">,</span>
        <span class="n">X_val</span><span class="p">,</span>
        <span class="n">y_val</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">,</span>
        <span class="n">warm_start</span><span class="p">,</span>
        <span class="n">in_bayes_opt</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ``pytorch_lightning`` implementation of training a pytorch model.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :meth:`AbstractModel._train_single_model`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">AbstractNN</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;_new_model must return an AbstractNN instance, but got </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span>
            <span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="s2">&quot;The dataloader, val_dataloader 0, does not have many workers&quot;</span>
        <span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span>
            <span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="s2">&quot;The dataloader, train_dataloader, does not have many workers&quot;</span>
        <span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="s2">&quot;Checkpoint directory&quot;</span><span class="p">)</span>

        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">Data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">X_train</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]),</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">RandomSampler</span><span class="p">(</span>
                <span class="n">data_source</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">),</span>
            <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">val_loader</span> <span class="o">=</span> <span class="n">Data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">X_val</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X_val</span><span class="p">),</span>
            <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">es_callback</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span>
            <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;early_stopping_eval&quot;</span><span class="p">,</span>
            <span class="n">min_delta</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
            <span class="n">patience</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">static_params</span><span class="p">[</span><span class="s2">&quot;patience&quot;</span><span class="p">],</span>
            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">ckpt_callback</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span>
            <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;early_stopping_eval&quot;</span><span class="p">,</span>
            <span class="n">dirpath</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span>
            <span class="n">save_top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span>
            <span class="n">every_n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">pl_loss_callback</span> <span class="o">=</span> <span class="n">PytorchLightningLossCallback</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">total_epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

        <span class="p">(</span>
            <span class="n">model</span><span class="o">.</span><span class="n">default_optimizer</span><span class="p">,</span>
            <span class="n">model</span><span class="o">.</span><span class="n">default_optimizer_params</span><span class="p">,</span>
            <span class="n">model</span><span class="o">.</span><span class="n">default_lr_scheduler</span><span class="p">,</span>
            <span class="n">model</span><span class="o">.</span><span class="n">default_lr_scheduler_params</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_optimizer_lr_scheduler_params</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">lightning_kwargs</span> <span class="o">=</span> <span class="n">update_defaults_by_kwargs</span><span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="n">min_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">fast_dev_run</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">max_time</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span> <span class="k">else</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
                <span class="n">accumulate_grad_batches</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">gradient_clip_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">overfit_batches</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                <span class="n">deterministic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">profiler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">logger</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">precision</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lightning_trainer_kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
            <span class="n">max_epochs</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">pl_loss_callback</span><span class="p">,</span> <span class="n">es_callback</span><span class="p">,</span> <span class="n">ckpt_callback</span><span class="p">],</span>
            <span class="n">enable_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">check_val_every_n_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">enable_checkpointing</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="o">**</span><span class="n">lightning_kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">with</span> <span class="n">HiddenPrints</span><span class="p">(</span>
            <span class="n">disable_std</span><span class="o">=</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">,</span>
            <span class="n">disable_logging</span><span class="o">=</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                <span class="n">model</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_dataloaders</span><span class="o">=</span><span class="n">val_loader</span>
            <span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt_callback</span><span class="o">.</span><span class="n">best_model_path</span><span class="p">)[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">])</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">remove_checkpoint</span><span class="p">(</span><span class="n">ckpt_callback</span><span class="o">.</span><span class="n">best_model_path</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_losses</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">pl_loss_callback</span><span class="o">.</span><span class="n">train_ls</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">pl_loss_callback</span><span class="o">.</span><span class="n">val_ls</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">restored_epochs</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
            <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;epoch=([0-9]*)-&quot;</span><span class="p">,</span> <span class="n">ckpt_callback</span><span class="o">.</span><span class="n">kth_best_model_path</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="c1"># pl.Trainer is not pickle-able. When pickling, &quot;ReferenceError: weakly-referenced object no longer exists.&quot;</span>
        <span class="c1"># may be raised occasionally. Set the trainer to None.</span>
        <span class="c1"># https://deepforest.readthedocs.io/en/latest/FAQ.html</span>
        <span class="n">model</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span></div>


<div class="viewcode-block" id="TorchModel._pred_single_model">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel._pred_single_model.html#tabensemb.model.TorchModel._pred_single_model">[docs]</a>
    <span class="k">def</span> <span class="nf">_pred_single_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;AbstractNN&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">Data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">X_test</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">y_test_pred</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">test_epoch</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">y_test_pred</span></div>


<div class="viewcode-block" id="TorchModel._space">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel._space.html#tabensemb.model.TorchModel._space">[docs]</a>
    <span class="k">def</span> <span class="nf">_space</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">SPACE</span></div>


<div class="viewcode-block" id="TorchModel._initial_values">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel._initial_values.html#tabensemb.model.TorchModel._initial_values">[docs]</a>
    <span class="k">def</span> <span class="nf">_initial_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">chosen_params</span></div>


<div class="viewcode-block" id="TorchModel.count_params">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModel.count_params.html#tabensemb.model.TorchModel.count_params">[docs]</a>
    <span class="k">def</span> <span class="nf">count_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">trainable_only</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Count the number of parameters in a ``torch.nn.Module``</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name</span>
<span class="sd">            The name of the selected model</span>
<span class="sd">        trainable_only</span>
<span class="sd">            Only count trainable (requires_grad=True) parameters.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The number of parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_custom_datamodule</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_model</span><span class="p">(</span>
                <span class="n">model_name</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_params</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">if</span> <span class="n">trainable_only</span> <span class="k">else</span> <span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span></div>
</div>



<div class="viewcode-block" id="AbstractWrapper">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractWrapper.html#tabensemb.model.AbstractWrapper">[docs]</a>
<span class="k">class</span> <span class="nc">AbstractWrapper</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    For those required deep learning models, this is a wrapper to make them have hidden information like</span>
<span class="sd">    ``hidden_representation`` or something else extracted from the forward process.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    hidden_rep_dim</span>
<span class="sd">    hidden_representation</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AbstractWrapper.__init__">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractWrapper.html#tabensemb.model.AbstractWrapper.__init__">[docs]</a>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">AbstractModel</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_model_names</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;More than one model is included in the input model base: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">get_model_names</span><span class="p">()</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wrapped_model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wrapped_model</span><span class="o">.</span><span class="n">get_model_names</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">original_forward</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wrap_forward</span><span class="p">()</span></div>


    <span class="k">def</span> <span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">item</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wrapped_model</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>

<div class="viewcode-block" id="AbstractWrapper.eval">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractWrapper.eval.html#tabensemb.model.AbstractWrapper.eval">[docs]</a>
    <span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span></div>


<div class="viewcode-block" id="AbstractWrapper.__call__">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractWrapper.__call__.html#tabensemb.model.AbstractWrapper.__call__">[docs]</a>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">derived_tensors</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Simulate ``AbstractNN._forward`` by calling ``AbstractNN.call_required_model``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">AbstractNN</span><span class="o">.</span><span class="n">call_required_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wrapped_model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">derived_tensors</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbstractWrapper.wrap_forward">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractWrapper.wrap_forward.html#tabensemb.model.AbstractWrapper.wrap_forward">[docs]</a>
    <span class="k">def</span> <span class="nf">wrap_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Override the forward method of a torch.nn.Module to record hidden representations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


<div class="viewcode-block" id="AbstractWrapper.reset_forward">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractWrapper.reset_forward.html#tabensemb.model.AbstractWrapper.reset_forward">[docs]</a>
    <span class="k">def</span> <span class="nf">reset_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reset the overridden forward method of the torch.nn.Module to ensure pickling compatibility.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hidden_rep_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The dimension of :meth:`hidden_representation`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hidden_representation</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The extracted information of a deep learning model when forward-passing a batch. It is usually the input of the</span>
<span class="sd">        last output layer (usually a linear layer or an MLP).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_forward</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wrap_forward</span><span class="p">()</span></div>



<div class="viewcode-block" id="TorchModelWrapper">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModelWrapper.html#tabensemb.model.TorchModelWrapper">[docs]</a>
<span class="k">class</span> <span class="nc">TorchModelWrapper</span><span class="p">(</span><span class="n">AbstractWrapper</span><span class="p">):</span>
<div class="viewcode-block" id="TorchModelWrapper.__init__">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModelWrapper.html#tabensemb.model.TorchModelWrapper.__init__">[docs]</a>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">TorchModel</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TorchModelWrapper</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span></div>


<div class="viewcode-block" id="TorchModelWrapper.wrap_forward">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModelWrapper.wrap_forward.html#tabensemb.model.TorchModelWrapper.wrap_forward">[docs]</a>
    <span class="k">def</span> <span class="nf">wrap_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span></div>


<div class="viewcode-block" id="TorchModelWrapper.reset_forward">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.TorchModelWrapper.reset_forward.html#tabensemb.model.TorchModelWrapper.reset_forward">[docs]</a>
    <span class="k">def</span> <span class="nf">reset_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hidden_rep_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">wrapped_model</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">]</span><span class="o">.</span><span class="n">hidden_rep_dim</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hidden_representation</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">wrapped_model</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">]</span><span class="o">.</span><span class="n">hidden_representation</span></div>



<div class="viewcode-block" id="AbstractNN">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.html#tabensemb.model.AbstractNN">[docs]</a>
<span class="k">class</span> <span class="nc">AbstractNN</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A subclass of ``pytorch_lightning.LightningModule`` that is compatible with :class:`TorchModel` and has implemented</span>
<span class="sd">    training and inferencing steps.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    default_loss_fn</span>
<span class="sd">        The name of the default loss function returned by :meth:`get_loss_fn`</span>
<span class="sd">    default_output_norm</span>
<span class="sd">        The name of the default output normalization returned by :meth:`get_output_norm`</span>
<span class="sd">    cont_feature_names</span>
<span class="sd">        The names of continuous features</span>
<span class="sd">    cat_feature_names</span>
<span class="sd">        The names of categorical features</span>
<span class="sd">    n_cont</span>
<span class="sd">        The number of continuous features</span>
<span class="sd">    n_cat</span>
<span class="sd">        The number of categorical features</span>
<span class="sd">    default_optimizer</span>
<span class="sd">        An optimizer name from ``torch.optim``.</span>
<span class="sd">    default_optimizer_params</span>
<span class="sd">        Parameters of :attr:`default_optimizer`</span>
<span class="sd">    default_lr_scheduler</span>
<span class="sd">        A lr scheduler name from ``torch.optim.lr_scheduler``</span>
<span class="sd">    default_lr_scheduler_params</span>
<span class="sd">        Parameters of :attr:`default_lr_scheduler`</span>
<span class="sd">    derived_feature_names</span>
<span class="sd">        The keys of derived unstacked features.</span>
<span class="sd">    derived_feature_dims</span>
<span class="sd">        The dimensions of derived unstacked features</span>
<span class="sd">    task</span>
<span class="sd">        &quot;regression&quot;, &quot;binary&quot;, or &quot;multiclass&quot;</span>
<span class="sd">    n_outputs</span>
<span class="sd">        The number of outputs. Note that for classification tasks, logits are returned instead of probabilities.</span>
<span class="sd">        For binary classification, the logit for the positive class is returned.</span>
<span class="sd">    cat_num_unique</span>
<span class="sd">        The number of unique values for each categorical feature.</span>
<span class="sd">    hidden_representation</span>
<span class="sd">        The extracted information of a deep learning model when forward-passing a batch.</span>
<span class="sd">        It is usually the input of the last output layer (usually a linear layer or an MLP). It should be manually</span>
<span class="sd">        recorded in :meth:`_forward`.</span>
<span class="sd">    hidden_rep_dim</span>
<span class="sd">        The dimension of :attr:`hidden_representation`. It should be manually set in :meth:`__init__`.</span>
<span class="sd">    device</span>
<span class="sd">    training</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AbstractNN.__init__">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.html#tabensemb.model.AbstractNN.__init__">[docs]</a>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datamodule</span><span class="p">:</span> <span class="n">DataModule</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Record useful information for initializing and training models.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        datamodule:</span>
<span class="sd">            A :class:`tabensemb.data.datamodule.DataModule` instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AbstractNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_loss_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_loss_fn</span><span class="p">(</span><span class="n">datamodule</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">task</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_output_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_norm</span><span class="p">(</span><span class="n">datamodule</span><span class="o">.</span><span class="n">task</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_optimizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_optimizer_params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_lr_scheduler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_lr_scheduler_params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cont_feature_names</span> <span class="o">=</span> <span class="n">cp</span><span class="p">(</span><span class="n">datamodule</span><span class="o">.</span><span class="n">cont_feature_names</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cat_feature_names</span> <span class="o">=</span> <span class="n">cp</span><span class="p">(</span><span class="n">datamodule</span><span class="o">.</span><span class="n">cat_feature_names</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_cont</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cont_feature_names</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_cat</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cat_feature_names</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">derived_feature_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">datamodule</span><span class="o">.</span><span class="n">derived_data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">derived_feature_dims</span> <span class="o">=</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">get_derived_data_sizes</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">derived_feature_names_dims</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">automatic_optimization</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_representation</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_rep_dim</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">=</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">task</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cont_feature_names</span><span class="p">)</span>
        <span class="n">task_outputs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;regression&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">datamodule</span><span class="o">.</span><span class="n">label_name</span><span class="p">),</span>
            <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">n_classes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="s2">&quot;binary&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="ow">in</span> <span class="n">task_outputs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span> <span class="o">=</span> <span class="n">task_outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported type of task </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cat_num_unique</span> <span class="o">=</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">cat_num_unique</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span>
                <span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span>
                <span class="n">ignore</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;trainer&quot;</span><span class="p">,</span> <span class="s2">&quot;datamodule&quot;</span><span class="p">,</span> <span class="s2">&quot;required_models&quot;</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="n">datamodule</span><span class="o">.</span><span class="n">derived_data</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">get_derived_data_sizes</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">derived_feature_names_dims</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_var</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span></div>


<div class="viewcode-block" id="AbstractNN.get_output_norm">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.get_output_norm.html#tabensemb.model.AbstractNN.get_output_norm">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_output_norm</span><span class="p">(</span><span class="n">task</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The operation on the output of ``forward`` in training/validation/testing steps. This will not affect the input</span>
<span class="sd">        of loss functions.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        task</span>
<span class="sd">            &quot;regression&quot;, &quot;multiclass&quot;, or &quot;binary&quot;</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        nn.Module</span>
<span class="sd">            The operation on the output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">task_norm</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;regression&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">(),</span>
            <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
            <span class="s2">&quot;binary&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">task_norm</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">task_norm</span><span class="p">[</span><span class="n">task</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unrecognized task </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbstractNN.get_loss_fn">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.get_loss_fn.html#tabensemb.model.AbstractNN.get_loss_fn">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_loss_fn</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">task</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The loss function for the output of ``forward`` and the target.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        loss</span>
<span class="sd">            &quot;cross_entropy&quot;, &quot;mae&quot;, or &quot;mse&quot;</span>
<span class="sd">        task</span>
<span class="sd">            &quot;regression&quot;, &quot;multiclass&quot;, or &quot;binary&quot;</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        nn.Module</span>
<span class="sd">            The loss function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">task</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">loss</span> <span class="o">!=</span> <span class="s2">&quot;cross_entropy&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Only cross entropy loss is supported for classification tasks.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>
            <span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;mse&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span>
                <span class="s2">&quot;mae&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">(),</span>
            <span class="p">}</span>
            <span class="k">return</span> <span class="n">mapping</span><span class="p">[</span><span class="n">loss</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unrecognized task </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The device where the model is.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_var</span><span class="o">.</span><span class="n">device</span>

<div class="viewcode-block" id="AbstractNN.forward">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.forward.html#tabensemb.model.AbstractNN.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">data_required_models</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A wrapper of the original forward of ``nn.Module`` for compatibility concerns.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensors:</span>
<span class="sd">            Input tensors to the torch model. They have the same structures as the ``tensors`` stored in</span>
<span class="sd">            :meth:`tabensemb.data.datamodule.DataModule`</span>
<span class="sd">        data_required_models:</span>
<span class="sd">            The datasets for required models processed by their own :meth:`AbstractModel._train_data_preprocess` or</span>
<span class="sd">            :meth:`AbstractModel._data_preprocess` methods. See :meth:`TorchModel._generate_dataset_for_required_models`</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The output from :meth:`_forward`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">tabensemb</span><span class="o">.</span><span class="n">setting</span><span class="p">[</span><span class="s2">&quot;test_with_no_grad&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span>
            <span class="k">else</span> <span class="n">torch_with_grad</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">additional_tensors</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">additional_tensors</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">additional_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">:</span>
                <span class="n">derived_tensors</span> <span class="o">=</span> <span class="n">additional_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">derived_tensors</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">additional_tensors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">derived_feature_names</span><span class="p">):</span>
                    <span class="n">derived_tensors</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
            <span class="k">if</span> <span class="n">data_required_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">derived_tensors</span><span class="p">[</span><span class="s2">&quot;data_required_models&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_required_models</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_representation</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">derived_tensors</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_representation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">hidden_representation</span> <span class="o">=</span> <span class="n">res</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_rep_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">hidden_rep_dim</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="AbstractNN._forward">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN._forward.html#tabensemb.model.AbstractNN._forward">[docs]</a>
    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">derived_tensors</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The real forward method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x</span>
<span class="sd">            A tensor that contains continuous features.</span>
<span class="sd">        derived_tensors</span>
<span class="sd">            It mostly has the same structure as the derived unstacked data ``derived_data`` stored in a</span>
<span class="sd">            :class:`tabensemb.data.datamodule.DataModule`. If some models are required (defined in</span>
<span class="sd">            :meth:`AbstractModel.required_models`), there will be a key named &quot;data_required_models&quot; containing the</span>
<span class="sd">            data batch, the output, and possibly the hidden representation of the required models.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The output of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        For classification tasks, DO NOT turn logits into probabilities here because we have already</span>
<span class="sd">        implemented this later. See also :meth:`output_norm`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


<div class="viewcode-block" id="AbstractNN.training_step">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.training_step.html#tabensemb.model.AbstractNN.training_step">[docs]</a>
    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="n">tensors</span><span class="p">,</span> <span class="n">data_required_models</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;self&quot;</span><span class="p">],</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;required&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensors</span><span class="p">,</span> <span class="n">data_required_models</span> <span class="o">=</span> <span class="n">batch</span><span class="p">,</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cal_zero_grad</span><span class="p">()</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">additional_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">1</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span>
            <span class="o">*</span><span class="p">([</span><span class="n">data</span><span class="p">]</span> <span class="o">+</span> <span class="n">additional_tensors</span><span class="p">),</span> <span class="n">data_required_models</span><span class="o">=</span><span class="n">data_required_models</span>
        <span class="p">)</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">before_loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">,</span> <span class="o">*</span><span class="p">([</span><span class="n">data</span><span class="p">]</span> <span class="o">+</span> <span class="n">additional_tensors</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cal_backward_step</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">default_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="s2">&quot;train_loss_verbose&quot;</span><span class="p">,</span>
            <span class="n">default_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
            <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="n">sch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedulers</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">is_last_batch</span> <span class="ow">and</span> <span class="n">sch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sch</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="AbstractNN.validation_step">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.validation_step.html#tabensemb.model.AbstractNN.validation_step">[docs]</a>
    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="n">tensors</span><span class="p">,</span> <span class="n">data_required_models</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;self&quot;</span><span class="p">],</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;required&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensors</span><span class="p">,</span> <span class="n">data_required_models</span> <span class="o">=</span> <span class="n">batch</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">additional_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">1</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span>
                <span class="o">*</span><span class="p">([</span><span class="n">data</span><span class="p">]</span> <span class="o">+</span> <span class="n">additional_tensors</span><span class="p">),</span>
                <span class="n">data_required_models</span><span class="o">=</span><span class="n">data_required_models</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">y</span><span class="p">,</span> <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">before_loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
            <span class="n">y_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_norm</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                <span class="s2">&quot;valid_loss_verbose&quot;</span><span class="p">,</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">yhat</span><span class="p">,</span> <span class="n">y_out</span></div>


<div class="viewcode-block" id="AbstractNN.configure_optimizers">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.configure_optimizers.html#tabensemb.model.AbstractNN.configure_optimizers">[docs]</a>
    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_optimizer</span><span class="p">)(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">default_optimizer_params</span>
        <span class="p">)</span>
        <span class="n">lrs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_lr_scheduler</span><span class="p">)(</span>
            <span class="n">optimizer</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">default_lr_scheduler_params</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr_scheduler&quot;</span><span class="p">:</span> <span class="n">lrs</span><span class="p">}</span></div>


<div class="viewcode-block" id="AbstractNN.test_epoch">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.test_epoch.html#tabensemb.model.AbstractNN.test_epoch">[docs]</a>
    <span class="k">def</span> <span class="nf">test_epoch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">:</span> <span class="n">Data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate a torch.nn.Module model in a single epoch.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        test_loader:</span>
<span class="sd">            The ``DataLoader`` of the testing dataset.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Parameters to train the model returned by :meth:`AbstractModel._get_params`. It contains all arguments in</span>
<span class="sd">            :meth:`AbstractModel._initial_values`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">            The prediction. Always a 2d ``torch.Tensor``.</span>
<span class="sd">        np.ndarray</span>
<span class="sd">            The ground truth. Always a 2d ``torch.Tensor``.</span>
<span class="sd">        float</span>
<span class="sd">            The default loss :meth:`get_loss_fn` of the model on the testing dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">truth</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">tabensemb</span><span class="o">.</span><span class="n">setting</span><span class="p">[</span><span class="s2">&quot;test_with_no_grad&quot;</span><span class="p">]</span>
            <span class="k">else</span> <span class="n">torch_with_grad</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="c1"># print(test_dataset)</span>
            <span class="n">avg_loss</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">:</span>
                    <span class="n">tensors</span><span class="p">,</span> <span class="n">data_required_models</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;self&quot;</span><span class="p">],</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;required&quot;</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">tensors</span><span class="p">,</span> <span class="n">data_required_models</span> <span class="o">=</span> <span class="n">batch</span><span class="p">,</span> <span class="kc">None</span>
                <span class="n">yhat</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">additional_tensors</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">1</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                <span class="p">]</span>
                <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span>
                    <span class="o">*</span><span class="p">([</span><span class="n">data</span><span class="p">]</span> <span class="o">+</span> <span class="n">additional_tensors</span><span class="p">),</span>
                    <span class="n">data_required_models</span><span class="o">=</span><span class="n">data_required_models</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">y</span><span class="p">,</span> <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">before_loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
                <span class="n">y_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_norm</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
                <span class="n">avg_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
                <span class="n">pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_out</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="n">truth</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yhat</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">avg_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">all_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">all_truth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">all_pred</span> <span class="o">=</span> <span class="n">all_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_truth</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">all_truth</span> <span class="o">=</span> <span class="n">all_truth</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">all_pred</span><span class="p">,</span> <span class="n">all_truth</span><span class="p">,</span> <span class="n">avg_loss</span></div>


<div class="viewcode-block" id="AbstractNN.before_loss_fn">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.before_loss_fn.html#tabensemb.model.AbstractNN.before_loss_fn">[docs]</a>
    <span class="k">def</span> <span class="nf">before_loss_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Treatments on the prediction and the ground truth before passing them to :meth:`loss_fn`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y</span>
<span class="sd">            The prediction from :meth:`forward`.</span>
<span class="sd">        yhat</span>
<span class="sd">            The ground truth.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The processed prediction</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The processed ground truth</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">yhat</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">yhat</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">yhat</span></div>


<div class="viewcode-block" id="AbstractNN.loss_fn">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.loss_fn.html#tabensemb.model.AbstractNN.loss_fn">[docs]</a>
    <span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        User defined loss function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y_true:</span>
<span class="sd">            The ground truth.</span>
<span class="sd">        y_pred:</span>
<span class="sd">            The predictions from the model (from :meth:`forward` and after :meth:`before_loss_fn`).</span>
<span class="sd">        *data:</span>
<span class="sd">            Tensors of continuous data and derived unstacked data.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Parameters to train the model returned by :meth:`AbstractModel._get_params`. It contains all arguments in</span>
<span class="sd">            :meth:`AbstractModel._initial_values`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            A torch-like loss.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Other attributes in ``self`` can also be used to calculate loss values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbstractNN.output_norm">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.output_norm.html#tabensemb.model.AbstractNN.output_norm">[docs]</a>
    <span class="k">def</span> <span class="nf">output_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        User defined operation before output. This is not related to the input of :meth:`loss_fn`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y_pred</span>
<span class="sd">            The prediction from the model (from :meth:`forward` and after :meth:`before_loss_fn`).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The modified prediction.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_output_norm</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbstractNN.cal_zero_grad">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.cal_zero_grad.html#tabensemb.model.AbstractNN.cal_zero_grad">[docs]</a>
    <span class="k">def</span> <span class="nf">cal_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call zero_grad of optimizers initialized in :meth:`configure_optimizers`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">opt</span><span class="p">:</span>
                <span class="n">o</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span></div>


<div class="viewcode-block" id="AbstractNN.cal_backward_step">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.cal_backward_step.html#tabensemb.model.AbstractNN.cal_backward_step">[docs]</a>
    <span class="k">def</span> <span class="nf">cal_backward_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform the backward propagation and optimization steps.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        loss</span>
<span class="sd">            The loss returned by :meth:`loss_fn`.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Other attributes recorded in :meth:`loss_fn` can be also used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">manual_backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span></div>


<div class="viewcode-block" id="AbstractNN.set_requires_grad">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.set_requires_grad.html#tabensemb.model.AbstractNN.set_requires_grad">[docs]</a>
    <span class="k">def</span> <span class="nf">set_requires_grad</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">requires_grad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set or reset requires_grad states of a ``nn.Module``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model</span>
<span class="sd">            A ``nn.Module`` model.</span>
<span class="sd">        requires_grad</span>
<span class="sd">            The requires_grad state for all parameters in the model.</span>
<span class="sd">        state</span>
<span class="sd">            The recorded state when calling this method with the argument ``required_grad`` given.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list</span>
<span class="sd">            The recorded state that can be used as the argument &quot;state&quot; to restore requires_grad states of the same</span>
<span class="sd">            model. Returned when the argument ``requires_grad`` is given.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">requires_grad</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="n">requires_grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;One of `requires_grad` and `state` should be specified to determine the action. If `requires_grad` is &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;not None, requires_grad of all parameters in the model is set. If state is not None, state of &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;requires_grad in the model is restored.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
                <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="n">state</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
                <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="n">requires_grad</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">state</span></div>


<div class="viewcode-block" id="AbstractNN._early_stopping_eval">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN._early_stopping_eval.html#tabensemb.model.AbstractNN._early_stopping_eval">[docs]</a>
    <span class="k">def</span> <span class="nf">_early_stopping_eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the loss value (criteria) for early stopping. The validation loss is returned, but note that</span>
<span class="sd">        ``0.0 * train_loss`` is added to the returned value so that NaNs in the training set can be detected by</span>
<span class="sd">        ``EarlyStopping``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        train_loss</span>
<span class="sd">            The training loss from :attr:`default_loss_fn` of the epoch.</span>
<span class="sd">        val_loss</span>
<span class="sd">            The validation loss from :attr:`default_loss_fn` of the epoch.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The early stopping evaluation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">val_loss</span> <span class="o">+</span> <span class="mf">0.0</span> <span class="o">*</span> <span class="n">train_loss</span></div>


<div class="viewcode-block" id="AbstractNN._test_required_model">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN._test_required_model.html#tabensemb.model.AbstractNN._test_required_model">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_test_required_model</span><span class="p">(</span>
        <span class="n">n_inputs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">required_model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">AbstractModel</span><span class="p">,</span> <span class="s2">&quot;AbstractNN&quot;</span><span class="p">,</span> <span class="n">AbstractWrapper</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test whether a required model has the attribute ``hidden_rep_dim`` and find its value.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_inputs</span>
<span class="sd">            The dimension of the input (i.e. the ``x`` of :meth:`_forward`)</span>
<span class="sd">        required_model</span>
<span class="sd">            A required model specified in :meth:`AbstractModel.required_models` and extracted by</span>
<span class="sd">            :meth:`AbstractModel._get_required_models`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool</span>
<span class="sd">            Whether the required model has the attribute ``hidden_rep_dim``</span>
<span class="sd">        int</span>
<span class="sd">             The dimension of the hidden representation. If the required model does not have the attribute</span>
<span class="sd">             ``hidden_rep_dim``, ``1+n_inputs`` is returned.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        For an ``AbstractNN``, whether the hidden representation (:attr:`hidden_representation`) is recorded is not</span>
<span class="sd">        guaranteed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">required_model</span><span class="p">,</span> <span class="n">AbstractWrapper</span><span class="p">):</span>
            <span class="n">hidden_rep_dim</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">required_model</span><span class="p">,</span> <span class="s2">&quot;hidden_rep_dim&quot;</span><span class="p">)</span>
            <span class="n">use_hidden_rep</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">required_model</span><span class="p">,</span> <span class="s2">&quot;hidden_representation&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span>
            <span class="n">required_model</span><span class="p">,</span> <span class="s2">&quot;hidden_rep_dim&quot;</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">required_model</span><span class="p">,</span> <span class="s2">&quot;hidden_rep_dim&quot;</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`hidden_rep_dim` is not given. The output of the backbone and the input features are used instead.&quot;</span>
                <span class="p">)</span>
                <span class="n">hidden_rep_dim</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">n_inputs</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">hidden_rep_dim</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">required_model</span><span class="p">,</span> <span class="s2">&quot;hidden_rep_dim&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">required_model</span><span class="p">,</span> <span class="s2">&quot;hidden_representation&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">required_model</span><span class="p">,</span> <span class="s2">&quot;hidden_rep_dim&quot;</span>
            <span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The backbone should have an attribute called `hidden_representation` that records the &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;final output of the hidden layer, and `hidden_rep_dim` that records the dim of &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;`hidden_representation`. The output of the backbone and the input features are used instead.&quot;</span>
                <span class="p">)</span>
            <span class="n">use_hidden_rep</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hidden_rep_dim</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">required_model</span><span class="p">,</span> <span class="s2">&quot;hidden_rep_dim&quot;</span><span class="p">)</span>
            <span class="n">use_hidden_rep</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="n">use_hidden_rep</span><span class="p">,</span> <span class="n">hidden_rep_dim</span></div>


<div class="viewcode-block" id="AbstractNN.call_required_model">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.call_required_model.html#tabensemb.model.AbstractNN.call_required_model">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">call_required_model</span><span class="p">(</span>
        <span class="n">required_model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">derived_tensors</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call a required model and return its result. Predictions and hidden representations are generated before</span>
<span class="sd">        training using this method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        required_model</span>
<span class="sd">            A required model specified in :meth:`AbstractModel.required_models` and extracted by</span>
<span class="sd">            :meth:`AbstractModel._get_required_models`.</span>
<span class="sd">        x</span>
<span class="sd">            See :meth:`_forward`.</span>
<span class="sd">        derived_tensors</span>
<span class="sd">            See :meth:`_forward`.</span>
<span class="sd">        model_name</span>
<span class="sd">            The name of the required model. It is necessary if the model comes from the same model base.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The result of the required model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If you want to run the required model and further train it, pass a copied</span>
<span class="sd">        ``derived_tensors`` after removing the ``{MODEL_NAME}_pred`` item in its ``data_required_models`` item.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
        <span class="n">full_name</span> <span class="o">=</span> <span class="n">TorchModel</span><span class="o">.</span><span class="n">get_full_name_from_required_model</span><span class="p">(</span>
            <span class="n">required_model</span><span class="p">,</span> <span class="n">model_name</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">full_name</span> <span class="o">+</span> <span class="s2">&quot;_pred&quot;</span> <span class="ow">in</span> <span class="n">derived_tensors</span><span class="p">[</span><span class="s2">&quot;data_required_models&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">dl_pred</span> <span class="o">=</span> <span class="n">derived_tensors</span><span class="p">[</span><span class="s2">&quot;data_required_models&quot;</span><span class="p">][</span><span class="n">full_name</span> <span class="o">+</span> <span class="s2">&quot;_pred&quot;</span><span class="p">][</span>
                <span class="mi">0</span>
            <span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dl_pred</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">dl_pred</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># This will only happen when generating datasets before training.</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">required_model</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">required_model</span><span class="p">,</span> <span class="n">AbstractWrapper</span>
            <span class="p">):</span>
                <span class="n">required_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                <span class="n">dl_pred</span> <span class="o">=</span> <span class="n">required_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">derived_tensors</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">required_model</span><span class="p">,</span> <span class="n">AbstractModel</span><span class="p">):</span>
                <span class="c1"># _pred_single_model might disturb random sampling of dataloaders because</span>
                <span class="c1"># in torch.utils.data._BaseDataLoaderIter.__init__, the following line uses random:</span>
                <span class="c1"># self._base_seed = torch.empty((), dtype=torch.int64).random_(generator=loader.generator).item()</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">required_model</span><span class="o">.</span><span class="n">get_model_names</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">ml_pred</span> <span class="o">=</span> <span class="n">required_model</span><span class="o">.</span><span class="n">_pred_single_model</span><span class="p">(</span>
                    <span class="n">required_model</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">name</span><span class="p">],</span>
                    <span class="n">X_test</span><span class="o">=</span><span class="n">derived_tensors</span><span class="p">[</span><span class="s2">&quot;data_required_models&quot;</span><span class="p">][</span><span class="n">full_name</span><span class="p">],</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">dl_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ml_pred</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">dl_pred</span></div>


<div class="viewcode-block" id="AbstractNN.get_hidden_state">
<a class="viewcode-back" href="../../../api/generated/tabensemb.model.AbstractNN.get_hidden_state.html#tabensemb.model.AbstractNN.get_hidden_state">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_hidden_state</span><span class="p">(</span>
        <span class="n">required_model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">derived_tensors</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The input of the last layer of a deep learning model, i.e. the hidden representation, whose dimension is</span>
<span class="sd">        (batch_size, required_model.hidden_rep_dim). The definition can be different for different models, depending on</span>
<span class="sd">        the different implementations of :class:`AbstractWrapper` for different model bases.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        required_model</span>
<span class="sd">            A required model specified in :meth:`AbstractModel.required_models` and extracted by</span>
<span class="sd">            :meth:`AbstractModel._get_required_models`.</span>
<span class="sd">        x</span>
<span class="sd">            See :meth:`_forward`.</span>
<span class="sd">        derived_tensors</span>
<span class="sd">            See :meth:`_forward`.</span>
<span class="sd">        model_name</span>
<span class="sd">            The name of the required model. It is necessary if the model comes from the same model base.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The input of the last layer of a deep learning model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
        <span class="n">full_name</span> <span class="o">=</span> <span class="n">TorchModel</span><span class="o">.</span><span class="n">get_full_name_from_required_model</span><span class="p">(</span>
            <span class="n">required_model</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">full_name</span> <span class="o">+</span> <span class="s2">&quot;_hidden&quot;</span> <span class="ow">in</span> <span class="n">derived_tensors</span><span class="p">[</span><span class="s2">&quot;data_required_models&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">hidden</span> <span class="o">=</span> <span class="n">derived_tensors</span><span class="p">[</span><span class="s2">&quot;data_required_models&quot;</span><span class="p">][</span><span class="n">full_name</span> <span class="o">+</span> <span class="s2">&quot;_hidden&quot;</span><span class="p">][</span>
                <span class="mi">0</span>
            <span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hidden</span> <span class="o">=</span> <span class="n">required_model</span><span class="o">.</span><span class="n">hidden_representation</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hidden</span></div>
</div>



<span class="k">class</span> <span class="nc">ModelDict</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;.pkl&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">((</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">),</span> <span class="n">file</span><span class="p">,</span> <span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">value</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="p">[</span><span class="n">item</span><span class="p">],</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="n">key</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s2">&quot;leaky_relu&quot;</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">nonlinearity</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">AdaptiveDropout</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">keep_dropout</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">global_p</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AdaptiveDropout</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span>
            <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="k">if</span> <span class="n">AdaptiveDropout</span><span class="o">.</span><span class="n">global_p</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">AdaptiveDropout</span><span class="o">.</span><span class="n">global_p</span><span class="p">,</span>
            <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">or</span> <span class="n">AdaptiveDropout</span><span class="o">.</span><span class="n">keep_dropout</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">set</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">keep_dropout</span> <span class="o">=</span> <span class="n">state</span>


<span class="k">class</span> <span class="nc">KeepDropout</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>

    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">AdaptiveDropout</span><span class="o">.</span><span class="n">keep_dropout</span>
        <span class="n">AdaptiveDropout</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">AdaptiveDropout</span><span class="o">.</span><span class="n">global_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span>

    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">):</span>
        <span class="n">AdaptiveDropout</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">)</span>
        <span class="n">AdaptiveDropout</span><span class="o">.</span><span class="n">global_p</span> <span class="o">=</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">get_sequential</span><span class="p">(</span>
    <span class="n">layers</span><span class="p">,</span>
    <span class="n">n_inputs</span><span class="p">,</span>
    <span class="n">n_outputs</span><span class="p">,</span>
    <span class="n">act_func</span><span class="p">,</span>
    <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">use_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">norm_type</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span>
    <span class="n">out_activate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">out_norm_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">adaptive_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;batch&quot;</span><span class="p">:</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span>
    <span class="k">elif</span> <span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;layer&quot;</span><span class="p">:</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Normalization </span><span class="si">{</span><span class="n">norm_type</span><span class="si">}</span><span class="s2"> not implemented.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">act_func</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">:</span>
        <span class="n">nonlinearity</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span>
    <span class="k">elif</span> <span class="n">act_func</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">:</span>
        <span class="n">nonlinearity</span> <span class="o">=</span> <span class="s2">&quot;leaky_relu&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">nonlinearity</span> <span class="o">=</span> <span class="s2">&quot;leaky_relu&quot;</span>
    <span class="k">if</span> <span class="n">adaptive_dropout</span><span class="p">:</span>
        <span class="n">dp</span> <span class="o">=</span> <span class="n">AdaptiveDropout</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_norm</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;norm_0&quot;</span><span class="p">,</span> <span class="n">norm</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">))</span>
        <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
            <span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">get_linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">nonlinearity</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;activate_0&quot;</span><span class="p">,</span> <span class="n">act_func</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dropout_0&quot;</span><span class="p">,</span> <span class="n">dp</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">use_norm</span><span class="p">:</span>
                <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;norm_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">norm</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]))</span>
            <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                <span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                <span class="n">get_linear</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">layers</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">nonlinearity</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;activate_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">act_func</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">dropout</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dropout_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">dp</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">out_norm_dropout</span> <span class="ow">and</span> <span class="n">use_norm</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;norm_out&quot;</span><span class="p">,</span> <span class="n">norm</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
            <span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="n">get_linear</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_outputs</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">nonlinearity</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">out_activate</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;activate_out&quot;</span><span class="p">,</span> <span class="n">act_func</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">out_norm_dropout</span> <span class="ow">and</span> <span class="n">dropout</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dropout_out&quot;</span><span class="p">,</span> <span class="n">dp</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_norm</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">norm</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">))</span>
        <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;single_layer&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">))</span>
        <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;activate&quot;</span><span class="p">,</span> <span class="n">act_func</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;dropout&quot;</span><span class="p">,</span> <span class="n">dp</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>

    <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">init_weights</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">nonlinearity</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">net</span>


<span class="k">def</span> <span class="nf">get_linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s2">&quot;leaky_relu&quot;</span><span class="p">):</span>
    <span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span>
    <span class="n">init_weights</span><span class="p">(</span><span class="n">linear</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">nonlinearity</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">linear</span>


<span class="k">class</span> <span class="nc">PytorchLightningLossCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">total_epoch</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PytorchLightningLossCallback</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_ls</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_ls</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">es_val_ls</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_epoch</span> <span class="o">=</span> <span class="n">total_epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_start</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;pl.Trainer&quot;</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">:</span> <span class="s2">&quot;pl.LightningModule&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">:</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">:</span> <span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">callback_metrics</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;train_loss_verbose&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;valid_loss_verbose&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_ls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">train_loss</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_ls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">val_loss</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">pl_module</span><span class="p">,</span> <span class="s2">&quot;_early_stopping_eval&quot;</span><span class="p">):</span>
            <span class="n">early_stopping_eval</span> <span class="o">=</span> <span class="n">pl_module</span><span class="o">.</span><span class="n">_early_stopping_eval</span><span class="p">(</span>
                <span class="n">trainer</span><span class="o">.</span><span class="n">logged_metrics</span><span class="p">[</span><span class="s2">&quot;train_loss_verbose&quot;</span><span class="p">],</span>
                <span class="n">trainer</span><span class="o">.</span><span class="n">logged_metrics</span><span class="p">[</span><span class="s2">&quot;valid_loss_verbose&quot;</span><span class="p">],</span>
            <span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">pl_module</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;early_stopping_eval&quot;</span><span class="p">,</span> <span class="n">early_stopping_eval</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">es_val_ls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">early_stopping_eval</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">early_stopping_eval</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">epoch</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">current_epoch</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">tabensemb</span><span class="o">.</span><span class="n">setting</span><span class="p">[</span><span class="s2">&quot;verbose_per_epoch&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">early_stopping_eval</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">total_epoch</span><span class="si">}</span><span class="s2">, Train loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Min val loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_ls</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Min ES val loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">es_val_ls</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Epoch time: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">start_time</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">s.&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">total_epoch</span><span class="si">}</span><span class="s2">, Train loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Min val loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_ls</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Epoch time: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">start_time</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">s.&quot;</span>
                <span class="p">)</span>


<span class="k">class</span> <span class="nc">DataFrameDataset</span><span class="p">(</span><span class="n">Data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="c1"># If predicting for a new dataframe, the index might be a mess.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">())</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_dict</span><span class="p">[</span><span class="n">item</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">NDArrayDataset</span><span class="p">(</span><span class="n">Data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">array</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">array</span> <span class="o">=</span> <span class="n">array</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">array</span><span class="p">[</span><span class="n">item</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">SubsetDataset</span><span class="p">(</span><span class="n">Data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">Data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Data</span><span class="o">.</span><span class="n">Subset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">item</span><span class="p">])</span>


<span class="k">class</span> <span class="nc">ListDataset</span><span class="p">(</span><span class="n">Data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datasets</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
        <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All datasets should have the equal length.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">DictDataset</span><span class="p">(</span><span class="n">Data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ls_dataset</span><span class="p">:</span> <span class="n">ListDataset</span><span class="p">,</span> <span class="n">keys</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="o">=</span> <span class="n">keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">ls_dataset</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="n">data</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">item</span><span class="p">))</span>
        <span class="p">}</span>


<span class="k">class</span> <span class="nc">DictDataFrameDataset</span><span class="p">(</span><span class="n">DictDataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dict_dfs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]):</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dict_dfs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">df_ls</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dict_dfs</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">ls_dataset</span> <span class="o">=</span> <span class="n">ListDataset</span><span class="p">([</span><span class="n">DataFrameDataset</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">df_ls</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DictDataFrameDataset</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">ls_dataset</span><span class="o">=</span><span class="n">ls_dataset</span><span class="p">,</span> <span class="n">keys</span><span class="o">=</span><span class="n">keys</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">DictNDArrayDataset</span><span class="p">(</span><span class="n">DictDataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dict_array</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]):</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dict_array</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">array_ls</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dict_array</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">ls_dataset</span> <span class="o">=</span> <span class="n">ListDataset</span><span class="p">([</span><span class="n">NDArrayDataset</span><span class="p">(</span><span class="n">array</span><span class="p">)</span> <span class="k">for</span> <span class="n">array</span> <span class="ow">in</span> <span class="n">array_ls</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DictNDArrayDataset</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">ls_dataset</span><span class="o">=</span><span class="n">ls_dataset</span><span class="p">,</span> <span class="n">keys</span><span class="o">=</span><span class="n">keys</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">DictMixDataset</span><span class="p">(</span><span class="n">DictDataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dict_mix</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]):</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dict_mix</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">item_ls</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dict_mix</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">ls_data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">item_ls</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
                <span class="n">ls_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DataFrameDataset</span><span class="p">(</span><span class="n">item</span><span class="p">))</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">ls_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">NDArrayDataset</span><span class="p">(</span><span class="n">item</span><span class="p">))</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">ls_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span><span class="n">item</span><span class="p">))</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
                <span class="n">ls_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SubsetDataset</span><span class="p">(</span><span class="n">item</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Generating a mixed type dataset for type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

        <span class="n">ls_dataset</span> <span class="o">=</span> <span class="n">ListDataset</span><span class="p">(</span><span class="n">ls_data</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DictMixDataset</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">ls_dataset</span><span class="o">=</span><span class="n">ls_dataset</span><span class="p">,</span> <span class="n">keys</span><span class="o">=</span><span class="n">keys</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_predict_with_ndarray</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">all_feature_names</span><span class="p">,</span> <span class="n">modelbase</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">datamodule</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">all_feature_names</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">modelbase</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
        <span class="n">df</span><span class="p">,</span>
        <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
        <span class="n">derived_data</span><span class="o">=</span><span class="n">datamodule</span><span class="o">.</span><span class="n">derive_unstacked</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">categorical_only</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">ignore_absence</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_bayes_objective</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">pass</span>
</pre></div>

                </article>
              
              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
       Copyright 2023, Tabular Ensemble developers.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.5.
    <br/>
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>